{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is written by Fengyu Zhong, aiming to build a number of functions and tools that can replicate the data analysis work\n",
    "done previously by excel.\n",
    "\n",
    "The sample codes are labeled deliberately by e.g a1, a2, c1 etc. It is aiming to provide a guide to the order of function usage. The order are also implied in return and input variable names.\n",
    "\n",
    "The dataframes which are the same but achieved by different function calls (i.e those obtained directly by calling large functions and those obtained by calling small functions step by step) will be named the same in example codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import seaborn as sns\n",
    "\n",
    "#let python display all columns on output.\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File_Assember( ):\n",
    "Read one or multiple concatenated files into a dataframe.\n",
    "\n",
    "Input: file path.\n",
    "\n",
    "Output: A pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the file path, users can change to their own paths\n",
    "path_ = r'C:\\Users\\Eric Zhong\\Documents\\2.INTERNSHIP\\RESEARCH\\iFiles_for_Leo'\n",
    "\n",
    "#The function passes in the file path and file_no_, which means the number of file in order. \n",
    "#For example, we want to read the 5th txt file only: File_Assembler(path_, 5, 5)\n",
    "#If we want to read files 1 - 7: File_Assembler(path_, 1, 7)\n",
    "#in total 58 txt files for now\n",
    "\n",
    "def File_Assembler(path_, file_lwr_, file_upper_):\n",
    "    all_files = glob.glob(path_ + \"/*.txt\")\n",
    "    count = 0\n",
    "    #create an empty array, and use a for loop to append files to the array.\n",
    "    li = []\n",
    "    for filename in all_files:\n",
    "        count = count + 1\n",
    "        if count >= file_lwr_ and count <= file_upper_:\n",
    "            x = pd.read_csv(filename, index_col=None, header=0, sep = '\\t')\n",
    "            li.append(x)\n",
    "    Assembled_File = pd.concat(li, axis=0, ignore_index=True)\n",
    "    return Assembled_File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R:\\ProgramFiles\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3254: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "df = File_Assembler(path_, 17, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File_Loader( )\n",
    "Used when the user only wants to load one file as an alternative\n",
    "\n",
    "INPUT:\n",
    "    File path\n",
    "    The number of file\n",
    "\n",
    "OUTPUT:\n",
    "    Dataframe containing the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since now the scenario has changed, File_assembler is no longer needed at most times. A File_loader is written below\n",
    "#in order to load single files more efficiently. User passes in the path and also the order number of file.\n",
    "def File_Loader(path_, file_no_):\n",
    "    all_files = glob.glob(path_ + \"/*.txt\")\n",
    "    count = 0\n",
    "    for filename in all_files:\n",
    "        count = count + 1\n",
    "        if count == file_no_:\n",
    "            file_ = pd.read_csv(filename, index_col=None, header=0, sep = '\\t')\n",
    "    return file_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NONOX_data: A BIG function that reproduces the excel sheet's NONOX data, leaving only PMAX\n",
    "Input\n",
    "    Data from File_Assembler or File_Loader\n",
    "    Time_alignment_constant, which is found to be 265 CAD in excel sheet 255\n",
    "    TDC, EVO, EVC: 600, 128, 382 in excel sheet.\n",
    "    NOoffset: The magical -390 constant when calculating NO average\n",
    "    Engine cycle period: 720 for ours\n",
    "Output\n",
    "    Dataframe that contains all NONOX data in excel sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def NONOX_data(Assembled_Data, time_alignment_constant_, TDC, EVO, EVC, NOoffset,Start_Crank_Angle = 75000, Engine_Cycle_Period_ = 720):\n",
    "#-------------------------------------------------tidy up the original dataframe-----------------------------------------\n",
    "    #replace variable names for convenience\n",
    "    a = Assembled_Data\n",
    "    p = Engine_Cycle_Period_\n",
    "    SCA = Start_Crank_Angle\n",
    "    # drop all unneccessary columns, and the units row.\n",
    "    a = a[['Crank Angle', 'NO', 'NOx']].drop([0])\n",
    "    # change data types from strings to floats\n",
    "    a = a.astype('float64')\n",
    "    # drop all rows with 0 values\n",
    "    a = a[a.NO != 0.0000]\n",
    "    #reset the index and drop original index column\n",
    "    a = a.reset_index().drop(['index'], axis=1)\n",
    "    #set crank angle as the index\n",
    "    a = a.set_index('Crank Angle')\n",
    "    \n",
    "#---------------------------------------------Generate basic data from existing data----------------------------------------\n",
    "    # Create two columns for NONOX in ppm\n",
    "    a['NO_ppm'] = a['NO'] * 200\n",
    "    a['NOx_ppm'] = a['NOx'] * 200\n",
    "    # Create NOx time aligned by shifting Nox_ppm values up by time constant amount \n",
    "    a['NOx_ppm_ta'] = a['NOx_ppm'].shift(-time_alignment_constant_)\n",
    "    # Create NO2 column\n",
    "    a['NO2'] = a['NOx_ppm_ta'] - a['NO_ppm']\n",
    "    # Create NO2/NOx column\n",
    "    a['NO2/NOx'] = a['NO2'] / a['NOx_ppm_ta']\n",
    "\n",
    "#---------------------------------------------Generate Average NO, NOx since CAD 75000--------------------------------------\n",
    "    # Fill the columns since CAD 75000\n",
    "    x = 0\n",
    "    while (x*p - NOoffset + TDC + EVC < a.shape[0]):\n",
    "        a.loc[SCA+x, 'NO_Avg'] = a['NO_ppm'].loc[SCA + x*p - NOoffset + TDC + EVO : SCA + x*p - NOoffset + TDC + EVC].mean()\n",
    "        a.loc[SCA+x, 'NOx_Avg'] = a['NOx_ppm'].loc[SCA + x*p + TDC + EVO : SCA + x*p + TDC + EVC].mean()\n",
    "        x = x + 1\n",
    "#--------------------------------------------NO2 avg and NO2/No avg--------------------------------------------------------\n",
    "    a['NO2_Avg'] = a['NOx_Avg'] - a['NO_Avg']\n",
    "    a['NO2/NO_Avg'] = a['NO2_Avg'] / a['NOx_Avg']\n",
    "\n",
    "#-----------------------------------------------add a time frame-----------------------------------------------------------\n",
    "    Avg_Time = []\n",
    "    for value in a.index:\n",
    "        Avg_Time.append((360 + value)*0.04)\n",
    "    a['Avg_Time'] = Avg_Time\n",
    "    a['Avg_Time'] = a['Avg_Time'].shift(SCA + 360)\n",
    "\n",
    "#----------------------------------------------------------------------clean up--------------------------------------------\n",
    "#truncate data from SCA\n",
    "    a = a[SCA:]\n",
    "#drop all rows with NAN values as they are not useful\n",
    "    a = a.dropna()\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = NONOX_data(a, time_alignment_constant_=265,TDC=600,EVO=128,EVC=382,NOoffset=390)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################Break the above function into small ones ############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter_NONOX( ):\n",
    "    This function filters the original dataframe to contain only NO, NOx (V) indexed by crank angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Filter_NONOX(Assembled_Data):\n",
    "#-------------------------------------------------tidy up the original dataframe-----------------------------------------\n",
    "    #replace variable names for convenience\n",
    "    a = Assembled_Data\n",
    "    # drop all unneccessary columns, and the units row.\n",
    "    a = a[['Crank Angle', 'NO', 'NOx']].drop([0])\n",
    "    # change data types from strings to floats\n",
    "    a = a.astype('float64')\n",
    "    # drop all rows with 0 values\n",
    "    a = a[a.NO != 0.0000]\n",
    "    #reset the index and drop original index column\n",
    "    a = a.reset_index().drop(['index'], axis=1)\n",
    "    #set crank angle as the index\n",
    "    a = a.set_index('Crank Angle')\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = Filter_NONOX(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TimeAlignmentNO2( )\n",
    "With the user supplying NONOX filtered dataframe:\n",
    "    This function adds columns for:\n",
    "        NO NOX in ppm\n",
    "        NOX timealigned\n",
    "        NO2 and NO2/NOX\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TimeAlignmentNO2(Filter_NONOX_Output_, time_alignment_constant_):\n",
    "#-------------------------------------------------tidy up the original dataframe-----------------------------------------\n",
    "    #replace variable names for convenience\n",
    "    a = Filter_NONOX_Output_\n",
    "    \n",
    "#---------------------------------------------Generate basic data from existing data----------------------------------------\n",
    "    # Create two columns for NONOX in ppm\n",
    "    a['NO_ppm'] = a['NO'] * 200\n",
    "    a['NOx_ppm'] = a['NOx'] * 200\n",
    "    # Create NOx time aligned by shifting Nox_ppm values up by time constant amount \n",
    "    a['NOx_ppm_ta'] = a['NOx_ppm'].shift(-time_alignment_constant_)\n",
    "    # Create NO2 column\n",
    "    a['NO2'] = a['NOx_ppm_ta'] - a['NO_ppm']\n",
    "    # Create NO2/NOx column\n",
    "    a['NO2/NOx'] = a['NO2'] / a['NOx_ppm_ta']\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = TimeAlignmentNO2(b1, time_alignment_constant_ = 265)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NONOX_Cyclic_Avg( ):\n",
    "    A funtion that calculates the average of NO NOx within sampling window from CAD 75000 onwards, and generate NO2 NO2/NOX average.\n",
    "\n",
    "INPUT:\n",
    "    Output of TimeAlignmentNO2\n",
    "    TDC EVO EVC\n",
    "    NOoffset: the magical 390 in excel sheet 255\n",
    "    Engine period of 720\n",
    "OUTPUT: \n",
    "    After this function, one should be able to obtain a dataframe containing all NONOX data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NONOX_Cyclic_Avg(TimeAlignmentNO2_Output_, TDC, EVO, EVC, NOoffset,Start_Crank_Angle=75000):\n",
    "    #simplify variable name for convenience\n",
    "    Engine_Cycle_Period_=720\n",
    "    SCA = Start_Crank_Angle\n",
    "    a = TimeAlignmentNO2_Output_\n",
    "    p = Engine_Cycle_Period_\n",
    "    x = 0\n",
    "    while (x*p - NOoffset + TDC + EVC < a.shape[0]):\n",
    "        a.loc[SCA+x, 'NO_Avg'] = a['NO_ppm'].loc[SCA + x*p - NOoffset + TDC + EVO : SCA + x*p - NOoffset + TDC + EVC].mean()\n",
    "        a.loc[SCA+x, 'NOx_Avg'] = a['NOx_ppm'].loc[SCA + x*p + TDC + EVO : SCA + x*p + TDC + EVC].mean()\n",
    "        x = x + 1\n",
    "        \n",
    "    a['NO2_Avg'] = a['NOx_Avg'] - a['NO_Avg']\n",
    "    a['NO2/NO_Avg'] = a['NO2_Avg'] / a['NOx_Avg']\n",
    "\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NONOX_Avg_Correspondence(output_NONOX_Cyclic_Avg,TDC,EVO,EVC,NOoffset,SCA):\n",
    "    Engine_Cycle_Period = 720\n",
    "    T = Engine_Cycle_Period\n",
    "    p = output_NONOX_Cyclic_Avg\n",
    "    p = p[SCA:]\n",
    "    p1 = p[['NO_ppm','NOx_ppm_ta','NO2','NO2/NOx']]\n",
    "    p1['NO_Avg_samplecycle'] = np.nan\n",
    "    p1['NOx_Avg_samplecycle'] = np.nan\n",
    "    p1['NO2_Avg_samplecycle'] = np.nan\n",
    "    p1['NO2/NOx_Avg_samplecycle'] = np.nan\n",
    "    i = p1.index[-1]\n",
    "    l = SCA-NOoffset+TDC+EVO\n",
    "    r = SCA-NOoffset+TDC+EVC\n",
    "    x = 0\n",
    "    while (x*T + r) <= i:\n",
    "        p1['NO_Avg_samplecycle'][(x*T+l):(x*T+r)]=p1['NO_ppm'][SCA+x]\n",
    "        p1['NOx_Avg_samplecycle'][(x*T+l):(x*T+r)]=p1['NOx_ppm_ta'][SCA+x]\n",
    "        p1['NO2_Avg_samplecycle'][(x*T+l):(x*T+r)]=p1['NO2'][SCA+x]\n",
    "        p1['NO2/NOx_Avg_samplecycle'][(x*T+l):(x*T+r)]=p1['NO2/NOx'][SCA+x]\n",
    "        x = x + 1\n",
    "    o1 = p[['NO_ppm','NOx_ppm_ta','NO2','NO2/NOx']]\n",
    "    p1 = p1.drop(['NO_ppm','NOx_ppm_ta','NO2','NO2/NOx'],axis = 1)\n",
    "    p3 = pd.concat([o1,p1],axis=1)\n",
    "    p3 = p3.dropna()\n",
    "    return p3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = NONOX_Cyclic_Avg(c1, TDC=600, EVO=128,EVC=382,NOoffset=390)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NONOX_Avg_Correspondence(d1,TC,EO,EC,OS,SA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NO_NOx_plotter( )\n",
    "Plots NO NOx data against crank angle.\n",
    "\n",
    "Input:\n",
    "    The NONOx filtered dataframe.\n",
    "    Start and end CAD he wishes to plot, by default 0 - 4319999.\n",
    "    Whether to plot NO, NOx or both\n",
    "    y lower and upper limit, 0 and 9 by default, which is the range of the entire dataframe.\n",
    "\n",
    "Output: NO NOX plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NONOX_v_plotter(Filtered_data_, NOoffset_, Start_Crank_Angle_ = -360, End_Crank_Angle_ = 431640, plot_NO = True, plot_NOx = True, y_lower_limit_ = 0, y_upper_limit_ = 3):\n",
    "    axes = plt.gca()\n",
    "    a = Filtered_data_\n",
    "    c = NOoffset_\n",
    "    sca = Start_Crank_Angle_\n",
    "    eca = End_Crank_Angle_\n",
    "    yll = y_lower_limit_\n",
    "    yul = y_upper_limit_\n",
    "    #FROM EXCEL SHEET 255, CRANK ANGLE STARTS AT 75390, NO STARTS AT 75000\n",
    "    a['NOshifted'] = a['NO'].shift(c)\n",
    "    if plot_NO == True and plot_NOx == True:\n",
    "        a.reset_index().reset_index().iloc[sca + 360 : eca + 360].plot(kind='line', x='index', y='NOshifted', label = 'NO', ylim = (yll , yul), ax=axes)\n",
    "        a.reset_index().reset_index().iloc[sca + 360 : eca + 360].plot(kind='line', x='index', y='NOx', ylim = (yll , yul), ax=axes)\n",
    "    elif plot_NO == True and plot_NOx == False:\n",
    "        a.reset_index().reset_index().iloc[sca + 360 : eca + 360].plot(kind='line', x='index', y='NOshifted', label = 'NO', ylim = (yll , yul), ax=axes)\n",
    "    else:\n",
    "        a.reset_index().reset_index().iloc[sca + 360 : eca + 360].plot(kind='line', x='index', y='NOx', ylim = (yll , yul), ax=axes)\n",
    "    axes.set(xlabel=\"Crank Angle\", ylabel=\"V\")\n",
    "    a.drop(columns=['NOshifted'])\n",
    "    plt.show()\n",
    "#as an example, we want to plot from \"engine\", from 205000 CAD to 215000 degree, the variation of NOx only:\n",
    "#NO_NOx_plotter(engine, 205000, 215000, False, True)\n",
    "#or, as False = 0, and True = 1:\n",
    "#NO_NOx_plotter(engine, 205000, 215000, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NONOX_in_V = NONOX_v_plotter(d1, NOoffset_=390, Start_Crank_Angle_=75000,End_Crank_Angle_=77000,plot_NO=True,plot_NOx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NONOX_ppm_plotter(Filtered_data_, NOoffset_, Start_Crank_Angle_ = -360, End_Crank_Angle_ = 431640, plot_NO = True, plot_NOx = True, plot_ratio = True, y_lower_limit_ = 0, y_upper_limit_ = 600, ylwrlmt_right = -0.5, yuprlmt_right = 0.5):\n",
    "    axes = plt.gca()\n",
    "    a = Filtered_data_\n",
    "    c = NOoffset_\n",
    "    sca = Start_Crank_Angle_\n",
    "    eca = End_Crank_Angle_\n",
    "    yll = y_lower_limit_\n",
    "    yul = y_upper_limit_\n",
    "    yllr = ylwrlmt_right\n",
    "    yulr = yuprlmt_right\n",
    "    \n",
    "    #shifting the columns to plot as the excel sheets!\n",
    "    a['NOshifted_ppm'] = a['NO_ppm'].shift(-c)\n",
    "    a['NO2/NOxshifted'] = a['NO2/NOx'].shift(-c)\n",
    "    if plot_NO == True and plot_NOx == True and plot_ratio == True:\n",
    "        a.reset_index().reset_index().iloc[sca + 360 : eca + 360].plot(kind='line', x='index', y='NOshifted_ppm', label = 'NO_ppm', ylim = (yll , yul), ax=axes)\n",
    "        a.reset_index().reset_index().iloc[sca + 360 : eca + 360].plot(kind='line', x='index', y='NOx_ppm', ylim = (yll , yul), ax=axes)\n",
    "        a.reset_index().reset_index().iloc[sca + 360 : eca + 360].plot(kind='line', x='index', y='NO2/NOxshifted',secondary_y=True, label = 'NO2/NOx', ax=axes)\n",
    "        axes.right_ax.set_ylim(yllr,yulr)\n",
    "    elif plot_NO == True and plot_NOx == True and plot_ratio == False:\n",
    "        a.reset_index().reset_index().iloc[sca + 360 : eca + 360].plot(kind='line', x='index', y='NOshifted_ppm', label = 'NO_ppm', ylim = (yll , yul), ax=axes)\n",
    "        a.reset_index().reset_index().iloc[sca + 360 : eca + 360].plot(kind='line', x='index', y='NOx_ppm', ylim = (yll , yul), ax=axes)\n",
    "    elif plot_NO == True and plot_NOx == False and plot_ratio == True:\n",
    "        a.reset_index().reset_index().iloc[sca + 360 : eca + 360].plot(kind='line', x='index', y='NOshifted_ppm', label = 'NO_ppm', ylim = (yll , yul), ax=axes)\n",
    "        a.reset_index().reset_index().iloc[sca + 360 : eca + 360].plot(kind='line', x='index', y='NO2/NOxshifted',secondary_y=True, label = 'NO2/NOx', ax=axes)\n",
    "        axes.right_ax.set_ylim(yllr,yulr)\n",
    "    elif plot_NO == True and plot_NOx == False and plot_ratio == False:\n",
    "        a.reset_index().reset_index().iloc[sca + 360 : eca + 360].plot(kind='line', x='index', y='NOshifted_ppm', label = 'NO_ppm', ylim = (yll , yul), ax=axes)\n",
    "    elif plot_NO == False and plot_NOx == True and plot_ratio == True:\n",
    "        a.reset_index().reset_index().iloc[sca + 360 : eca + 360].plot(kind='line', x='index', y='NOx_ppm', ylim = (yll , yul), ax=axes)\n",
    "        a.reset_index().reset_index().iloc[sca + 360 : eca + 360].plot(kind='line', x='index', y='NO2/NOxshifted',secondary_y=True, label = 'NO2/NOx', ax=axes)\n",
    "        axes.right_ax.set_ylim(yllr,yulr)\n",
    "    elif plot_NO == False and plot_NOx == True and plot_ratio == False:\n",
    "        a.reset_index().reset_index().iloc[sca + 360 : eca + 360].plot(kind='line', x='index', y='NOx_ppm', ylim = (yll , yul), ax=axes)\n",
    "    elif plot_NO == False and plot_NOx == False and plot_ratio == True:\n",
    "        a.reset_index().reset_index().iloc[sca + 360 : eca + 360].plot(kind='line', x='index', y='NO2/NOxshifted',secondary_y=True, label = 'NO2/NOx', ax=axes)\n",
    "        axes.right_ax.set_ylim(yllr,yulr)\n",
    "    axes.set(xlabel=\"Crank Angle\", ylabel=\"ppm\")\n",
    "    #a = a.drop(columns=['NOshifted_ppm', 'NO2/NOxshifted'])\n",
    "    plt.show()\n",
    "    return a\n",
    "#as an example, we want to plot from \"engine\", from 205000 CAD to 215000 degree, the variation of NOx only:\n",
    "#NO_NOx_plotter(engine, 205000, 215000, False, True)\n",
    "#or, as False = 0, and True = 1:\n",
    "#NO_NOx_plotter(engine, 205000, 215000, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NONOX_in_ppm = NONOX_ppm_plotter(d1,NOoffset_=390,Start_Crank_Angle_=77000,End_Crank_Angle_=80000,plot_NO=True,plot_NOx=False,plot_ratio=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter_Shifted( )\n",
    "    The function aims to clean up and get rid of the extra shifted columns generated from the plots functions\n",
    "    as I did not manage to find a way to stop the functions generating the extra columns\n",
    "INPUT:\n",
    "    The dataframe after plots, two boolean variables to indicate whether the user has used the two plot functions\n",
    "    by default, the user is assumed to NOT have plotted, hence the function wont do anything\n",
    "\n",
    "OUTPUT:\n",
    "    Cleaned dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Filter_Shifted(Plots_Output, NO_v_plotted = False, NO_ratio_ppm_plotted = False):\n",
    "    a = Plots_Output\n",
    "    if NO_v_plotted == True and NO_ratio_ppm_plotted == True:\n",
    "        a = a.drop(columns = ['NOshifted', 'NOshifted_ppm', 'NO2/NOxshifted'])\n",
    "    elif NO_v_plotted == True and NO_ratio_ppm_plotted == False:\n",
    "        a = a.drop(columns = ['NOshifted'])\n",
    "    elif NO_v_plotted == False and NO_ratio_ppm_plotted == True:\n",
    "        a = a.drop(columns = ['NOshifted_ppm', 'NO2/NOxshifted'])\n",
    "\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e1 = Filter_Shifted(d1, NO_v_plotted=True, NO_ratio_ppm_plotted= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time( )\n",
    "    This function calculates the average time taken after each crank angle, and allows user to input the starting crank angle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Time(dataframe, Start_Crank_Angle):\n",
    "    a = dataframe\n",
    "    s = Start_Crank_Angle\n",
    "    Avg_Time = []\n",
    "    for value in a.index:\n",
    "        Avg_Time.append((360 + value)*0.04)\n",
    "    a['Avg_Time'] = Avg_Time\n",
    "    a['Avg_Time'] = a['Avg_Time'].shift(s + 360)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f1 = Time(d1,75000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################## PRESSURE FUNCTIONS FROM NOW ON##############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PMAX_DATA( )\n",
    "    This a big function that takes in the raw data output from File_Assembler(). It returns a dataframe that contains PMAX\n",
    "    data indexed by the starting crank angle supplied by user, same as the work done in excel.\n",
    "    \n",
    "    Due to the length of the function, no comments are added.\n",
    "    \n",
    "    The function will be broken down into smaller parts later on, and the explanations and comments will be attached there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PMAX_DATA(Assembled_Data, Start_Crank_Angle_):\n",
    "    p = Assembled_Data\n",
    "    p = p[['Crank Angle', 'PCYL1']].drop([0]).astype('float64').set_index(['Crank Angle'])\n",
    "    \n",
    "    rand_sampling_index = np.random.randint(1,10)\n",
    "    sample_index = pd.DataFrame([1,2,3,4,5,6,7,8,9,10]).sample(frac = 1)\n",
    "\n",
    "    sample_n_360 = p.loc[-360].sample(n = 1)\n",
    "    \n",
    "    n1 = int((p.loc[-359:-1].count())/10)\n",
    "    randomizercolumn1 = pd.concat([sample_index] * n1)\n",
    "    randomizercolumn1.index = p.loc[-359:-1].index\n",
    "    t1 = pd.concat([randomizercolumn1, p.loc[-359:-1]], axis = 1)\n",
    "    t1 = t1[t1[0] == rand_sampling_index]\n",
    "    first_part = t1.drop([0], axis = 1)\n",
    "    \n",
    "    sample_0 = p.loc[0].sample(n = 1)\n",
    "        \n",
    "    n2 = int((p.loc[1:431639].count())/10)\n",
    "    randomizercolumn2 = pd.concat([sample_index] * n2)\n",
    "    randomizercolumn2.index = p.loc[1:431639].index\n",
    "    t2 = pd.concat([randomizercolumn2, p.loc[1:431639]], axis = 1)\n",
    "    t2 = t2[t2[0] == rand_sampling_index]\n",
    "    second_part = t2.drop([0], axis = 1)\n",
    "\n",
    "    sample_431640 = p.loc[431640].sample(n = 1)\n",
    "    \n",
    "    P_sampled = pd.concat([sample_n_360, first_part, sample_0, second_part, sample_431640])\n",
    "    \n",
    "    Period_ = 720\n",
    "    SCA = Start_Crank_Angle_\n",
    "    PMAX_ = pd.DataFrame([], columns = ['PMAX', 'Crank Angle']).set_index('Crank Angle')\n",
    "    x = 0\n",
    "\n",
    "    while ((SCA+Period_*(x+1)-1) < P_sampled.shape[0]):\n",
    "        PMAX_.loc[SCA+x] = float(P_sampled.loc[SCA+Period_*x:SCA+Period_*(x+1)-1].max())\n",
    "        x = x + 1\n",
    "        \n",
    "    return PMAX_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = PMAX_DATA(a, 75000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter_PCYL1( ):\n",
    "\n",
    "Input:\n",
    "    Data from File_Assembler or File_Loader.\n",
    "\n",
    "Output: \n",
    "    Dataframe that contains only Crank Angle, PCYL1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Filter_PCYL1(Assembled_Data):\n",
    "    P_Dataframe_ = Assembled_Data\n",
    "    # drop all unneccessary columns, and the units row.\n",
    "    P_Dataframe_ = P_Dataframe_[['Crank Angle', 'PCYL1']].drop([0])\n",
    "    # change data types from strings to floats\n",
    "    P_Dataframe_ = P_Dataframe_.astype('float64')\n",
    "    #reset the index and drop original index column\n",
    "    P_Dataframe_ = P_Dataframe_.set_index(['Crank Angle'])\n",
    "    #Assembled_Data_filtered = Assembled_Data_filtered.reset_index().drop(['index'], axis=1)\n",
    "    #Make Crank Angle start at 0 instead of -360\n",
    "    #Assembled_Data_filtered['Crank Angle'] = Assembled_Data_filtered['Crank Angle'] + 360\n",
    "\n",
    "    return P_Dataframe_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b2 = Filter_PCYL1(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Psample( ) returns a dataframe that contains sampled PCYL1 data.\n",
    "\n",
    "The relatively quick sampling is achieved by appending a column of integer 1 to 10 in random order, and sample a specific\n",
    "row with a random number generated at start of the function.\n",
    "\n",
    "With CAD -360, 0, 431640 containing less than 10 rows, we have to treat them separately, hence the entire function\n",
    "contains 5 parts. In the end, we concatenate them all together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    " def Psample(P_Dataframe_):\n",
    "    p = P_Dataframe_\n",
    "    \n",
    "    #generate a random integer for sampling\n",
    "    rand_sampling_index = np.random.randint(1,10)\n",
    "    #create index 1:10\n",
    "    sample_index = pd.DataFrame([1,2,3,4,5,6,7,8,9,10])\n",
    "    #Randomize the sample_index\n",
    "    sample_index = sample_index.sample(frac = 1)\n",
    "    \n",
    "    \n",
    "    #randomly sample a data for -ve 360\n",
    "    sample_n_360 = P_Dataframe_.loc[-360].sample(n = 1)\n",
    "\n",
    "    #deal with all CADs inbetween -360 and 0\n",
    "    #dupilicate random index by [(rows -359:-1 )/10 = n1] number of times\n",
    "    n1 = int((p.loc[-359:-1].count())/10)\n",
    "    #concatenate all 1-10 repeats for n1 times in a column\n",
    "    randomizercolumn1 = pd.concat([sample_index] * n1)\n",
    "    #copy the index of input DataFrame, which is 'Crank Angle', to the newly created randomizer column\n",
    "    randomizercolumn1.index = p.loc[-359:-1].index\n",
    "    #Now that both the dataframe and randomizer column are indexed by 'Crank Angle', we concatenate them side by side\n",
    "    t1 = pd.concat([randomizercolumn1, p.loc[-359:-1]], axis = 1)\n",
    "    #Use the random number generated at first to sample. The randomizer column has column name as '0'\n",
    "    t1 = t1[t1[0] == rand_sampling_index]\n",
    "    #Now drop the randomizer column with column name '0'.\n",
    "    first_part = t1.drop([0], axis = 1)\n",
    "    \n",
    "    #Deal with 0\n",
    "    sample_0 = p.loc[0].sample(n = 1)\n",
    "        \n",
    "    #all CADS inbetween 0 and 431640 same before.\n",
    "    n2 = int((p.loc[1:431639].count())/10)\n",
    "    randomizercolumn2 = pd.concat([sample_index] * n2)\n",
    "    randomizercolumn2.index = p.loc[1:431639].index\n",
    "    t2 = pd.concat([randomizercolumn2, p.loc[1:431639]], axis = 1)\n",
    "    t2 = t2[t2[0] == rand_sampling_index]\n",
    "    second_part = t2.drop([0], axis = 1)\n",
    "\n",
    "    #Deal with 431640\n",
    "    sample_431640 = p.loc[431640].sample(n = 1)\n",
    "    \n",
    "    #concatenate all 5 parts together vertically.\n",
    "    P_sampled = pd.concat([sample_n_360, first_part, sample_0, second_part, sample_431640])\n",
    "    \n",
    "    \n",
    "    return P_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c2 = Psample(b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Psample_MAXMAX( )\n",
    "    This is a test function which instead of sampling, take the maximum PCLY1 per CAD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Psample_MAXMAX(P_Dataframe_):\n",
    "    p = P_Dataframe_\n",
    "    P_sampled = P_Dataframe_.groupby(p.index).max()\n",
    "    return P_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c2 = Psample_MAXMAX(b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PMAX( ):\n",
    "Extracts cyclic maximum PCYL1.\n",
    "\n",
    "INPUT:\n",
    "    PCYL1 filtered dataframe\n",
    "    Offset of engine cycle (how much CAD does the engine go through before the first recorded cycle)\n",
    "    Engine cycle period\n",
    "OUTPUT:\n",
    "    A dataframe that contains maximum PCYL1 for every engine cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PMAX(P_sampled, Start_Crank_Angle_ = -360):\n",
    "    Period_ = 720\n",
    "    SCA = Start_Crank_Angle_\n",
    "    PMAX_ = pd.DataFrame([], columns = ['PMAX', 'Crank Angle']).set_index('Crank Angle')\n",
    "    x = 0\n",
    "\n",
    "    while ((SCA+Period_*(x+1)-1) < P_sampled.shape[0]):\n",
    "        #Find the max pressure value for every 720 degree cycle, append to the PMAX_ dataframe.\n",
    "        PMAX_.loc[SCA+x] = float(P_sampled.loc[SCA+Period_*x:SCA+Period_*(x+1)-1].max())\n",
    "        #increment x\n",
    "        x = x + 1\n",
    "        \n",
    "    return PMAX_\n",
    "#The output dataframe should have its index as the number of cycles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d2 = PMAX(c2, Start_Crank_Angle_=75000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge_PMAX_NONOX()\n",
    "    Merge the two input NONOX and Pmax dataframe together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Merge_PMAX_NONOX(NONOX_Dataframe_, Pmax_Dataframe_):\n",
    "    df1 = NONOX_Dataframe_\n",
    "    df2 = Pmax_Dataframe_\n",
    "    df3 = pd.concat([df1, df2], axis = 1)\n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "Merged = Merge_PMAX_NONOX(d1, d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merged.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation_NOavg_PMAX() makes a scatter plot of NONOX and also returns R value, the default limits are set according excel files, for reasons which i dont know of.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Correlation_NOavg_PMAX_plot(Merged_Pmax_NONOX_dataframe, PMAXlower_CAD = 75005, PMAXupper_CAD = 75145, NONOXlower_CAD = 75000, NONOXupper_CAD = 75140, plotNO = True, plotNOX = False):\n",
    "    df3 = Merged_Pmax_NONOX_dataframe\n",
    "    pl = PMAXlower_CAD\n",
    "    pu = PMAXupper_CAD\n",
    "    nl = NONOXlower_CAD\n",
    "    nu = NONOXupper_CAD\n",
    "    #Regression plots with \n",
    "    if plotNO == True and plotNOX == False:\n",
    "        sns.regplot(y=df3['PMAX'].loc[pl:pu],x=df3['NO_Avg'].loc[nl:nu],data=df3,fit_reg=True)\n",
    "        Rsquared = (df3['PMAX'].loc[pl:pu]).corr(df3['NO_Avg'].loc[nl:nu])\n",
    "        print('NO: Rsquared =',Rsquared)\n",
    "    elif plotNOX == True and plotNO == False:\n",
    "        sns.regplot(y=df3['PMAX'].loc[pl:pu],x=df3['NOx_Avg'].loc[nl:nu],data=df3,fit_reg=True)\n",
    "        Rsquared = (df3['PMAX'].loc[pl:pu]).corr(df3['NOx_Avg'].loc[nl:nu])\n",
    "        print('NOx: Rsquared =',Rsquared)\n",
    "    return Rsquared\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation_NOavg_PMAX_plot(m, PMAXlower_CAD=75000,PMAXupper_CAD=75140,NONOXlower_CAD=75001,NONOXupper_CAD=75141,plotNO=False,plotNOX=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NO2_NOx_ratio_vs_avgtime()\n",
    "    plots a scatter plot of the ratio against avg time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NO2_NOx_ratio_vs_avgtime(DataframeWithTime_, Start_Crank_Angle_, End_Crank_Angle_):\n",
    "    df = DataframeWithTime_\n",
    "    SCA = Start_Crank_Angle_\n",
    "    ECA = End_Crank_Angle_\n",
    "    df1 = df[SCA:ECA]\n",
    "    df1.plot.scatter(x='Avg_Time',y='NO2/NO_Avg', c='DarkBlue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NO2_NOx_ratio_vs_avgtime(f1, 75000, 431639)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------QUENCH AND DRIFT-------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DriftCorrections( )\n",
    "    Replicate the 'drift correction' excel sheet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In specifying the path, one should alway add an 'r' in front so that '\\' is treated as a raw string\n",
    "#The filename, together with path are used to read source files. filename should always contain '.xlsx'\n",
    "#'file' is used with ranges excel file, so dont need to contain .xlsx\n",
    "#As shown in the example here\n",
    "path = r'C:\\Users\\Eric Zhong\\Documents\\2.INTERNSHIP\\RESEARCH\\Fast_NOx-20200612T071734Z-001\\Fast_NOx'\n",
    "file = '1500 3bar cycle analysis.xlsx'\n",
    "filename = '1500 3bar cycle analysis.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Large_Drift_Quench_Correction(NONOXdataframe,path,filename,RunNumber_,FuelHC,FuelOC,slowdataranges_path):\n",
    "#---------------------------------------------DriftCorrection(path, filename)----------------------------------------------\n",
    "    Driftdataframe = pd.read_excel(path+'\\\\'+filename, sheet_name = 'Drift corrections')\n",
    "    Driftdataframe = Driftdataframe.set_index('Unnamed: 0')\n",
    "#---------------------------------------------QuenchCorrection(FuelHC, FuelOC)-------------------------------------------------------\n",
    "    Quenchdataframe = pd.DataFrame([], columns = ['Lambda'])\n",
    "    Lambda_column = [((100 + 5*x)/100) for x in range(181)]    \n",
    "    Quenchdataframe['Lambda'] = Lambda_column\n",
    "    Quenchdataframe['CO2'] = 100/(1+(FuelHC/2)+(((4.773*Quenchdataframe['Lambda'])-1)*(1+(FuelHC/4)-(FuelOC/2))))\n",
    "    Quenchdataframe['H2O'] = 100*FuelHC/(2+FuelHC+2*(((4.773*Quenchdataframe['Lambda'])-1)*(1+(FuelHC/4)-(FuelOC/2))))\n",
    "    Quenchdataframe['O2'] = 100*(Quenchdataframe['Lambda']-1)*(1+(FuelHC/4)-(FuelOC/2))/(1+(FuelHC/2)+(((4.773*Quenchdataframe['Lambda'])-1)*(1+(FuelHC/4)-(FuelOC/2))))\n",
    "    Quenchdataframe['CLD quench'] = (1.34*Quenchdataframe['H2O'])+(0.26*Quenchdataframe['CO2'])\n",
    "#---------------------------------------------Slow_Data(path, filename)----------------------------------------------------\n",
    "    Slowdata = pd.read_excel(path+'\\\\'+filename, sheet_name='slow data', na_values=['NA'], usecols = \"CG:CO\")\n",
    "    Slowdata = Slowdata[1:].dropna()\n",
    "    Slowdata = Slowdata[['NO','NOx','MEXA Lambda']]\n",
    "    Slowdata = Slowdata.reset_index().drop(['index'], axis = 1)\n",
    "#---------------------------------------------Read_slow_data_ranges(slowdataranges_path)-----------------------------------\n",
    "    rangesfile = 'slowdataranges.xlsx'\n",
    "    Slow_data_ranges = pd.read_excel((path + '\\\\' + rangesfile), na_values=['NA'])\n",
    "#-----------------------------DriftCorrectedNONOXavg(NONOXdataframe_, DriftcorrectionDataframe_, RunNumber_)---------------\n",
    "    p = NONOXdataframe\n",
    "    c = RunNumber_\n",
    "    p['DriftCorrected_NO_Avg'] = (p['NO_Avg'] + Driftdataframe[c].loc['NO0'])/Driftdataframe[c].loc['NOS']\n",
    "    p['DriftCorrected_NOx_Avg'] = (p['NOx_Avg'] + Driftdataframe[c].loc['NOx0'])/Driftdataframe[c].loc['NOxS']\n",
    "    p['DriftCorrected_NO2_Avg'] = p['DriftCorrected_NOx_Avg'] - p['DriftCorrected_NO_Avg']\n",
    "#-------------Append_Slow_Data(NONOXDataframe,RangesDataframe,Slowdataframe,QuenchCorrectionDataframe,file,RunNumber)------\n",
    "    R = Slow_data_ranges\n",
    "    S = Slowdata\n",
    "    loc_low = c*2 - 2\n",
    "    loc_high = c*2 - 1\n",
    "    Lambda_low = int(R[file].loc[loc_low])\n",
    "    Lambda_high = int(R[file].loc[loc_high])\n",
    "    S1 = S[Lambda_low:Lambda_high]\n",
    "    n = p.shape[0]-S1.shape[0]\n",
    "    extender = pd.DataFrame({\"NO\":[np.nan]*n, \"NOx\":[np.nan]*n,\"MEXA Lambda\":[np.nan]*n}) \n",
    "    S1 = pd.concat([S1,extender]).reset_index().drop(['index'], axis = 1)\n",
    "    S1 = S1.set_index(p.index)\n",
    "    p2 = pd.concat([p,S1], axis = 1)\n",
    "    p2 = p2.rename(columns={\"NO\": \"Slow NO\", \"NOx\": \"Slow NOx\",\"MEXA Lambda\":\"Slow Lambda\"})\n",
    "#-------------------Append_QuenchCorrected_data(df_with_Driftcor_and_Slowdata, QuenchCorrection_output_df)-----------------\n",
    "    I = p2\n",
    "    Q = Quenchdataframe\n",
    "    Lrounded = []\n",
    "    for values in I['Slow Lambda']:\n",
    "        Lrounded.append(round(values, 1))\n",
    "    I['Lrounded'] = Lrounded\n",
    "    I2 = I.dropna()\n",
    "    CLDcol = []\n",
    "    for values in I2['Lrounded']:\n",
    "        n = float(Q[Q['Lambda'] == values].loc[:,'CLD quench'])\n",
    "        CLDcol.append(n)\n",
    "    I2['CLDquench'] = CLDcol\n",
    "    I = pd.concat([I,I2['CLDquench']],axis = 1)\n",
    "    #quench corrected NO avg\n",
    "    I['QuenchCorrected_NO_Avg'] = I['DriftCorrected_NO_Avg']*((100 + I['CLDquench'])/100)\n",
    "    #quench corrected NOx avg\n",
    "    I['QuenchCorrected_NOx_Avg'] = I['DriftCorrected_NOx_Avg']*((100 + I['CLDquench'])/100)\n",
    "    #quench corrected NO2 avg\n",
    "    I['QuenchCorrected_NO2_Avg'] = I['QuenchCorrected_NOx_Avg'] - I['QuenchCorrected_NO_Avg']\n",
    "    #quench corrected NO2/NOx avg\n",
    "    I['QuenchCorrected_NO2/NOx'] = I['QuenchCorrected_NO2_Avg']/I['QuenchCorrected_NOx_Avg']\n",
    "    return Driftdataframe,Quenchdataframe,I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R:\\ProgramFiles\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "(D,Q,result) = Large_Drift_Quench_Correction(Merged,path,1,filename,1.86,0,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DriftCorrection(path, filename):\n",
    "    drift = pd.read_excel(path+'\\\\'+filename, sheet_name = 'Drift corrections')\n",
    "    drift = drift.set_index('Unnamed: 0')\n",
    "    return drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = DriftCorrection(path,filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QuenchCorrection( )\n",
    "Reproduce the 'Quench Correction' excel sheet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QuenchCorrection(FuelHC, FuelOC):\n",
    "    #Create a lambda column\n",
    "    data = pd.DataFrame([], columns = ['Lambda'])\n",
    "\n",
    "    #Create the lambda column\n",
    "    #Using list comprehension to create a list of lambda 0 to 10.0 with step size 0.05\n",
    "    Lambda_column = [((100 + 5*x)/100) for x in range(181)]    \n",
    "    data['Lambda'] = Lambda_column\n",
    "    \n",
    "    #CO2 Column\n",
    "    data['CO2'] = 100/(1+(FuelHC/2)+(((4.773*data['Lambda'])-1)*(1+(FuelHC/4)-(FuelOC/2))))\n",
    "    #H2O\n",
    "    data['H2O'] = 100*FuelHC/(2+FuelHC+2*(((4.773*data['Lambda'])-1)*(1+(FuelHC/4)-(FuelOC/2))))\n",
    "    #O2\n",
    "    data['O2'] = 100*(data['Lambda']-1)*(1+(FuelHC/4)-(FuelOC/2))/(1+(FuelHC/2)+(((4.773*data['Lambda'])-1)*(1+(FuelHC/4)-(FuelOC/2))))\n",
    "    #CLD quench\n",
    "    data['CLD quench'] = (1.34*data['H2O'])+(0.26*data['CO2'])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = QuenchCorrection(1.86,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slow_Data( )\n",
    "    Get useful information out of the slow data excel sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Slow_Data(path, filename):\n",
    "    S = pd.read_excel(path+'\\\\'+filename, sheet_name='slow data', na_values=['NA'], usecols = \"CG:CO\")\n",
    "    #Drop the first row containing units, and NAN rows\n",
    "    S = S[1:].dropna()\n",
    "    #Drop all inrelevant columns\n",
    "    S = S[['NO','NOx','MEXA Lambda']]\n",
    "    #Reset the index and drop original index column\n",
    "    S = S.reset_index().drop(['index'], axis = 1)\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = Slow_Data(path,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Read_slow_data_ranges(slowdataranges_path):\n",
    "    file = 'slowdataranges.xlsx'\n",
    "    Slow_data_ranges = pd.read_excel((path + '\\\\' + file), na_values=['NA'])\n",
    "    #change all NaN values to \n",
    "    return Slow_data_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = Read_slow_data_ranges(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DriftCorrectedNONOXavg( )\n",
    "    Add 3 columns of drifted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DriftCorrectedNONOXavg(NONOXdataframe_, DriftcorrectionDataframe_, RunNumber_):\n",
    "    #change variable names for convenience\n",
    "    p = NONOXdataframe_\n",
    "    D = DriftcorrectionDataframe_\n",
    "    c = RunNumber_\n",
    "    #Calculate drift corrections\n",
    "    p['DriftCorrected_NO_Avg'] = (p['NO_Avg'] + D[c].loc['NO0'])/D[c].loc['NOS']\n",
    "    p['DriftCorrected_NOx_Avg'] = (p['NOx_Avg'] + D[c].loc['NOx0'])/D[c].loc['NOxS']\n",
    "    p['DriftCorrected_NO2_Avg'] = p['DriftCorrected_NOx_Avg'] - p['DriftCorrected_NO_Avg']\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = DriftCorrectedNONOXavg(Merged,D,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Correlation_Plotter(dataframe,var1,var2,var1_start,var1_end,var2_start,var2_end):\n",
    "    df3 = dataframe\n",
    "    v1s = var1_start\n",
    "    v1e = var1_end\n",
    "    v2s = var2_start\n",
    "    v2e = var2_end\n",
    "    \n",
    "    sns.regplot(y=df3[var1].loc[v1s:v1e],x=df3[var2].loc[v2s:v2e],data=df3,fit_reg=True)\n",
    "    Rsquared = (df3[var1].loc[v1s:v1e]).corr(df3[var2].loc[v2s:v2e])\n",
    "    print(var1,'vs', var2,'|','Rsquared =',Rsquared)\n",
    "    \n",
    "    return Rsquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation_Plotter(u,'PMAX','DriftCorrected_NO_Avg',75000,75140,75001,75141)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import_Lambda( )\n",
    "    Reads the lambda column from excel file and append it to the NONOXdataframe, so we can do quench analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Append_Slow_Data(NONOXDataframe,RangesDataframe,Slowdataframe,QuenchCorrectionDataframe,file,RunNumber):\n",
    "    p = NONOXDataframe\n",
    "    R = RangesDataframe\n",
    "    S = Slowdataframe\n",
    "    #find the location of the range limits in ranges dataframe\n",
    "    loc_low = RunNumber*2 - 2\n",
    "    loc_high = RunNumber*2 - 1\n",
    "    #Use the corresponding values at loc_low/loc_high to get ranges of lambda values to use\n",
    "    Lambda_low = int(R[file].loc[loc_low])\n",
    "    Lambda_high = int(R[file].loc[loc_high])\n",
    "    #[Lambda_low:Lambda_high] is the range of slow data to use at current filename, current runnumber.\n",
    "    S1 = S[Lambda_low:Lambda_high]\n",
    "    #extend the slow dataframe to the same size as NONOXDataframe, for concatenation.\n",
    "    n = p.shape[0]-S1.shape[0]\n",
    "    extender = pd.DataFrame({\"NO\":[np.nan]*n, \"NOx\":[np.nan]*n,\"MEXA Lambda\":[np.nan]*n}) \n",
    "    S1 = pd.concat([S1,extender]).reset_index().drop(['index'], axis = 1)\n",
    "    #set S1's index according to p1, crank angle degrees\n",
    "    S1 = S1.set_index(p.index)\n",
    "    #concatenate\n",
    "    p2 = pd.concat([p,S1], axis = 1)\n",
    "    p2 = p2.rename(columns={\"NO\": \"Slow NO\", \"NOx\": \"Slow NOx\",\"MEXA Lambda\":\"Slow Lambda\"})\n",
    "    \n",
    "    return p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "u1 = Append_Slow_Data(u,R,S,Q,file,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QuenchCorrectedNONOXNO2Ratio()\n",
    "    Add the 3 columns of Quench Corrected data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Append_QuenchCorrected_data(df_with_Driftcor_and_Slowdata, QuenchCorrection_output_df):\n",
    "    I = df_with_Driftcor_and_Slowdata\n",
    "    Q = QuenchCorrection_output_df\n",
    "    \n",
    "    #get a column of Lambda rounded to 1 d.p for algo speed\n",
    "    Lrounded = []\n",
    "    for values in I['Slow Lambda']:\n",
    "        Lrounded.append(round(values, 1))\n",
    "    I['Lrounded'] = Lrounded\n",
    "    \n",
    "    #Separate 'Lrounded' column out to deal with it individually\n",
    "    I2 = I.dropna()\n",
    "    CLDcol = []\n",
    "    for values in I2['Lrounded']:\n",
    "        n = float(Q[Q['Lambda'] == values].loc[:,'CLD quench'])\n",
    "        CLDcol.append(n)\n",
    "    I2['CLDquench'] = CLDcol\n",
    "    \n",
    "    I = pd.concat([I,I2['CLDquench']],axis = 1)\n",
    "    \n",
    "    #quench corrected NO avg\n",
    "    I['QuenchCorrected_NO_Avg'] = I['DriftCorrected_NO_Avg']*((100 + I['CLDquench'])/100)\n",
    "    #quench corrected NOx avg\n",
    "    I['QuenchCorrected_NOx_Avg'] = I['DriftCorrected_NOx_Avg']*((100 + I['CLDquench'])/100)\n",
    "    #quench corrected NO2 avg\n",
    "    I['QuenchCorrected_NO2_Avg'] = I['QuenchCorrected_NOx_Avg'] - I['QuenchCorrected_NO_Avg']\n",
    "    #quench corrected NO2/NOx avg\n",
    "    I['QuenchCorrected_NO2/NOx'] = I['QuenchCorrected_NO2_Avg']/I['QuenchCorrected_NOx_Avg']\n",
    "    \n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NO</th>\n",
       "      <th>NOx</th>\n",
       "      <th>NO_ppm</th>\n",
       "      <th>NOx_ppm</th>\n",
       "      <th>NOx_ppm_ta</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NO2/NOx</th>\n",
       "      <th>NO_Avg</th>\n",
       "      <th>NOx_Avg</th>\n",
       "      <th>NO2_Avg</th>\n",
       "      <th>NO2/NO_Avg</th>\n",
       "      <th>Avg_Time</th>\n",
       "      <th>PMAX</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crank Angle</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75000.0</th>\n",
       "      <td>1.8255</td>\n",
       "      <td>2.1059</td>\n",
       "      <td>365.10</td>\n",
       "      <td>421.18</td>\n",
       "      <td>414.04</td>\n",
       "      <td>48.94</td>\n",
       "      <td>0.118201</td>\n",
       "      <td>381.881882</td>\n",
       "      <td>430.438667</td>\n",
       "      <td>48.556784</td>\n",
       "      <td>0.112808</td>\n",
       "      <td>0.00</td>\n",
       "      <td>48.433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75001.0</th>\n",
       "      <td>1.8281</td>\n",
       "      <td>2.0932</td>\n",
       "      <td>365.62</td>\n",
       "      <td>418.64</td>\n",
       "      <td>418.38</td>\n",
       "      <td>52.76</td>\n",
       "      <td>0.126105</td>\n",
       "      <td>359.226667</td>\n",
       "      <td>403.820784</td>\n",
       "      <td>44.594118</td>\n",
       "      <td>0.110430</td>\n",
       "      <td>0.04</td>\n",
       "      <td>49.808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75002.0</th>\n",
       "      <td>1.8294</td>\n",
       "      <td>2.0817</td>\n",
       "      <td>365.88</td>\n",
       "      <td>416.34</td>\n",
       "      <td>419.66</td>\n",
       "      <td>53.78</td>\n",
       "      <td>0.128151</td>\n",
       "      <td>396.840863</td>\n",
       "      <td>448.315608</td>\n",
       "      <td>51.474745</td>\n",
       "      <td>0.114818</td>\n",
       "      <td>0.08</td>\n",
       "      <td>50.288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75003.0</th>\n",
       "      <td>1.8345</td>\n",
       "      <td>2.0715</td>\n",
       "      <td>366.90</td>\n",
       "      <td>414.30</td>\n",
       "      <td>421.70</td>\n",
       "      <td>54.80</td>\n",
       "      <td>0.129950</td>\n",
       "      <td>387.786275</td>\n",
       "      <td>457.503059</td>\n",
       "      <td>69.716784</td>\n",
       "      <td>0.152385</td>\n",
       "      <td>0.12</td>\n",
       "      <td>48.881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75004.0</th>\n",
       "      <td>1.8307</td>\n",
       "      <td>2.0689</td>\n",
       "      <td>366.14</td>\n",
       "      <td>413.78</td>\n",
       "      <td>423.22</td>\n",
       "      <td>57.08</td>\n",
       "      <td>0.134871</td>\n",
       "      <td>345.926196</td>\n",
       "      <td>396.022980</td>\n",
       "      <td>50.096784</td>\n",
       "      <td>0.126500</td>\n",
       "      <td>0.16</td>\n",
       "      <td>51.886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75490.0</th>\n",
       "      <td>1.9073</td>\n",
       "      <td>2.0115</td>\n",
       "      <td>381.46</td>\n",
       "      <td>402.30</td>\n",
       "      <td>445.44</td>\n",
       "      <td>63.98</td>\n",
       "      <td>0.143633</td>\n",
       "      <td>188.868235</td>\n",
       "      <td>225.317176</td>\n",
       "      <td>36.448941</td>\n",
       "      <td>0.161767</td>\n",
       "      <td>19.60</td>\n",
       "      <td>43.829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75491.0</th>\n",
       "      <td>1.9150</td>\n",
       "      <td>1.9949</td>\n",
       "      <td>383.00</td>\n",
       "      <td>398.98</td>\n",
       "      <td>442.62</td>\n",
       "      <td>59.62</td>\n",
       "      <td>0.134698</td>\n",
       "      <td>210.517490</td>\n",
       "      <td>250.192706</td>\n",
       "      <td>39.675216</td>\n",
       "      <td>0.158579</td>\n",
       "      <td>19.64</td>\n",
       "      <td>42.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75492.0</th>\n",
       "      <td>1.9124</td>\n",
       "      <td>1.9936</td>\n",
       "      <td>382.48</td>\n",
       "      <td>398.72</td>\n",
       "      <td>438.80</td>\n",
       "      <td>56.32</td>\n",
       "      <td>0.128350</td>\n",
       "      <td>179.517176</td>\n",
       "      <td>218.342275</td>\n",
       "      <td>38.825098</td>\n",
       "      <td>0.177818</td>\n",
       "      <td>19.68</td>\n",
       "      <td>42.742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75493.0</th>\n",
       "      <td>1.9099</td>\n",
       "      <td>1.9834</td>\n",
       "      <td>381.98</td>\n",
       "      <td>396.68</td>\n",
       "      <td>434.46</td>\n",
       "      <td>52.48</td>\n",
       "      <td>0.120794</td>\n",
       "      <td>172.879922</td>\n",
       "      <td>218.134275</td>\n",
       "      <td>45.254353</td>\n",
       "      <td>0.207461</td>\n",
       "      <td>19.72</td>\n",
       "      <td>43.573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75494.0</th>\n",
       "      <td>1.9175</td>\n",
       "      <td>1.9757</td>\n",
       "      <td>383.50</td>\n",
       "      <td>395.14</td>\n",
       "      <td>432.92</td>\n",
       "      <td>49.42</td>\n",
       "      <td>0.114155</td>\n",
       "      <td>196.092863</td>\n",
       "      <td>241.346379</td>\n",
       "      <td>45.253517</td>\n",
       "      <td>0.187504</td>\n",
       "      <td>19.76</td>\n",
       "      <td>42.550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>495 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 NO     NOx  NO_ppm  NOx_ppm  NOx_ppm_ta    NO2   NO2/NOx  \\\n",
       "Crank Angle                                                                 \n",
       "75000.0      1.8255  2.1059  365.10   421.18      414.04  48.94  0.118201   \n",
       "75001.0      1.8281  2.0932  365.62   418.64      418.38  52.76  0.126105   \n",
       "75002.0      1.8294  2.0817  365.88   416.34      419.66  53.78  0.128151   \n",
       "75003.0      1.8345  2.0715  366.90   414.30      421.70  54.80  0.129950   \n",
       "75004.0      1.8307  2.0689  366.14   413.78      423.22  57.08  0.134871   \n",
       "...             ...     ...     ...      ...         ...    ...       ...   \n",
       "75490.0      1.9073  2.0115  381.46   402.30      445.44  63.98  0.143633   \n",
       "75491.0      1.9150  1.9949  383.00   398.98      442.62  59.62  0.134698   \n",
       "75492.0      1.9124  1.9936  382.48   398.72      438.80  56.32  0.128350   \n",
       "75493.0      1.9099  1.9834  381.98   396.68      434.46  52.48  0.120794   \n",
       "75494.0      1.9175  1.9757  383.50   395.14      432.92  49.42  0.114155   \n",
       "\n",
       "                 NO_Avg     NOx_Avg    NO2_Avg  NO2/NO_Avg  Avg_Time    PMAX  \n",
       "Crank Angle                                                                   \n",
       "75000.0      381.881882  430.438667  48.556784    0.112808      0.00  48.433  \n",
       "75001.0      359.226667  403.820784  44.594118    0.110430      0.04  49.808  \n",
       "75002.0      396.840863  448.315608  51.474745    0.114818      0.08  50.288  \n",
       "75003.0      387.786275  457.503059  69.716784    0.152385      0.12  48.881  \n",
       "75004.0      345.926196  396.022980  50.096784    0.126500      0.16  51.886  \n",
       "...                 ...         ...        ...         ...       ...     ...  \n",
       "75490.0      188.868235  225.317176  36.448941    0.161767     19.60  43.829  \n",
       "75491.0      210.517490  250.192706  39.675216    0.158579     19.64  42.774  \n",
       "75492.0      179.517176  218.342275  38.825098    0.177818     19.68  42.742  \n",
       "75493.0      172.879922  218.134275  45.254353    0.207461     19.72  43.573  \n",
       "75494.0      196.092863  241.346379  45.253517    0.187504     19.76  42.550  \n",
       "\n",
       "[495 rows x 13 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
