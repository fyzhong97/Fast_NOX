{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is written by Fengyu Zhong, aiming to build a number of functions and tools that can replicate the data analysis work\n",
    "done previously by excel.\n",
    "\n",
    "The sample codes are labeled deliberately by e.g a1, a2, c1 etc. It is aiming to provide a guide to the order of function usage. The order are also implied in return and input variable names.\n",
    "\n",
    "The dataframes which are the same but achieved by different function calls (i.e those obtained directly by calling large functions and those obtained by calling small functions step by step) will be named the same in example codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import seaborn as sns\n",
    "\n",
    "#let python display all columns on output.\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File_Assember( ):\n",
    "Read one or multiple concatenated files into a dataframe.\n",
    "\n",
    "Input: file path.\n",
    "\n",
    "Output: A pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the file path, users can change to their own paths\n",
    "path_ = r'C:\\Users\\Eric Zhong\\Documents\\2.INTERNSHIP\\RESEARCH\\iFiles_for_Leo'\n",
    "\n",
    "#The function passes in the file path and file_no_, which means the number of file in order. \n",
    "#For example, we want to read the 5th txt file only: File_Assembler(path_, 5, 5)\n",
    "#If we want to read files 1 - 7: File_Assembler(path_, 1, 7)\n",
    "#in total 58 txt files for now\n",
    "\n",
    "def File_Assembler(path_, file_lwr_, file_upper_):\n",
    "    all_files = glob.glob(path_ + \"/*.txt\")\n",
    "    count = 0\n",
    "    #create an empty array, and use a for loop to append files to the array.\n",
    "    li = []\n",
    "    for filename in all_files:\n",
    "        count = count + 1\n",
    "        if count >= file_lwr_ and count <= file_upper_:\n",
    "            x = pd.read_csv(filename, index_col=None, header=0, sep = '\\t')\n",
    "            li.append(x)\n",
    "    Assembled_File = pd.concat(li, axis=0, ignore_index=True)\n",
    "    return Assembled_File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R:\\ProgramFiles\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3254: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "#df = File_Assembler(path_, 26, 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File_Loader( )\n",
    "Used when the user only wants to load one file as an alternative\n",
    "\n",
    "INPUT:\n",
    "    File path\n",
    "    The number of file\n",
    "\n",
    "OUTPUT:\n",
    "    Dataframe containing the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since now the scenario has changed, File_assembler is no longer needed at most times. A File_loader is written below\n",
    "#in order to load single files more efficiently. User passes in the path and also the order number of file.\n",
    "def File_Loader(path_, file_no_):\n",
    "    all_files = glob.glob(path_ + \"/*.txt\")\n",
    "    count = 0\n",
    "    for filename in all_files:\n",
    "        count = count + 1\n",
    "        if count == file_no_:\n",
    "            file_ = pd.read_csv(filename, index_col=None, header=0, sep = '\\t')\n",
    "    return file_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NONOX_data: A BIG function that reproduces the excel sheet's NONOX data, leaving only PMAX\n",
    "Input\n",
    "    Data from File_Assembler or File_Loader\n",
    "    Time_alignment_constant, which is found to be 265 CAD in excel sheet 255\n",
    "    TDC, EVO, EVC: 600, 128, 382 in excel sheet.\n",
    "    NOoffset: The magical -390 constant when calculating NO average\n",
    "    Engine cycle period: 720 for ours\n",
    "Output\n",
    "    Dataframe that contains all NONOX data in excel sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def NONOX_data(Assembled_Data, time_alignment_constant_, TDC, EVO, EVC, NOoffset,Start_Crank_Angle = 75000, Engine_Cycle_Period_ = 720):\n",
    "#-------------------------------------------------tidy up the original dataframe-----------------------------------------\n",
    "    #replace variable names for convenience\n",
    "    a = Assembled_Data\n",
    "    p = Engine_Cycle_Period_\n",
    "    SCA = Start_Crank_Angle\n",
    "    # drop all unneccessary columns, and the units row.\n",
    "    a = a[['Crank Angle', 'NO', 'NOx']].drop([0])\n",
    "    # change data types from strings to floats\n",
    "    a = a.astype('float64')\n",
    "    # drop all rows with 0 values\n",
    "    a = a[a.NO != 0.0000]\n",
    "    #reset the index and drop original index column\n",
    "    a = a.reset_index().drop(['index'], axis=1)\n",
    "    #set crank angle as the index\n",
    "    a = a.set_index('Crank Angle')\n",
    "    \n",
    "#---------------------------------------------Generate basic data from existing data----------------------------------------\n",
    "    # Create two columns for NONOX in ppm\n",
    "    a['NO_ppm'] = a['NO'] * 200\n",
    "    a['NOx_ppm'] = a['NOx'] * 200\n",
    "    # Create NOx time aligned by shifting Nox_ppm values up by time constant amount \n",
    "    a['NOx_ppm_ta'] = a['NOx_ppm'].shift(-time_alignment_constant_)\n",
    "    # Create NO2 column\n",
    "    a['NO2'] = a['NOx_ppm_ta'] - a['NO_ppm']\n",
    "    # Create NO2/NOx column\n",
    "    a['NO2/NOx'] = a['NO2'] / a['NOx_ppm_ta']\n",
    "\n",
    "#---------------------------------------------Generate Average NO, NOx since CAD 75000--------------------------------------\n",
    "    # Fill the columns since CAD 75000\n",
    "    x = 0\n",
    "    while (x*p - NOoffset + TDC + EVC < a.shape[0]):\n",
    "        a.loc[SCA+x, 'NO_Avg'] = a['NO_ppm'].loc[SCA + x*p - NOoffset + TDC + EVO : SCA + x*p - NOoffset + TDC + EVC].mean()\n",
    "        a.loc[SCA+x, 'NOx_Avg'] = a['NOx_ppm'].loc[SCA + x*p + TDC + EVO : SCA + x*p + TDC + EVC].mean()\n",
    "        x = x + 1\n",
    "#--------------------------------------------NO2 avg and NO2/No avg--------------------------------------------------------\n",
    "    a['NO2_Avg'] = a['NOx_Avg'] - a['NO_Avg']\n",
    "    a['NO2/NO_Avg'] = a['NO2_Avg'] / a['NOx_Avg']\n",
    "\n",
    "#-----------------------------------------------add a time frame-----------------------------------------------------------\n",
    "    Avg_Time = []\n",
    "    for value in a.index:\n",
    "        Avg_Time.append((360 + value)*0.04)\n",
    "    a['Avg_Time'] = Avg_Time\n",
    "    a['Avg_Time'] = a['Avg_Time'].shift(SCA + 360)\n",
    "\n",
    "#----------------------------------------------------------------------clean up--------------------------------------------\n",
    "#truncate data from SCA\n",
    "    a = a[SCA:]\n",
    "#drop all rows with NAN values as they are not useful\n",
    "    a = a.dropna()\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = NONOX_data(a, time_alignment_constant_=265,TDC=600,EVO=128,EVC=382,NOoffset=390)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NO</th>\n",
       "      <th>NOx</th>\n",
       "      <th>NO_ppm</th>\n",
       "      <th>NOx_ppm</th>\n",
       "      <th>NOx_ppm_ta</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NO2/NOx</th>\n",
       "      <th>NO_Avg</th>\n",
       "      <th>NOx_Avg</th>\n",
       "      <th>NO2_Avg</th>\n",
       "      <th>NO2/NO_Avg</th>\n",
       "      <th>Avg_Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crank Angle</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75000.0</th>\n",
       "      <td>0.10750</td>\n",
       "      <td>0.37659</td>\n",
       "      <td>21.500</td>\n",
       "      <td>75.318</td>\n",
       "      <td>73.276</td>\n",
       "      <td>51.776</td>\n",
       "      <td>0.706589</td>\n",
       "      <td>17.561976</td>\n",
       "      <td>69.219475</td>\n",
       "      <td>51.657498</td>\n",
       "      <td>0.746286</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75001.0</th>\n",
       "      <td>0.10750</td>\n",
       "      <td>0.36000</td>\n",
       "      <td>21.500</td>\n",
       "      <td>72.000</td>\n",
       "      <td>75.828</td>\n",
       "      <td>54.328</td>\n",
       "      <td>0.716464</td>\n",
       "      <td>21.408024</td>\n",
       "      <td>70.656808</td>\n",
       "      <td>49.248784</td>\n",
       "      <td>0.697014</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75002.0</th>\n",
       "      <td>0.11005</td>\n",
       "      <td>0.34979</td>\n",
       "      <td>22.010</td>\n",
       "      <td>69.958</td>\n",
       "      <td>78.126</td>\n",
       "      <td>56.116</td>\n",
       "      <td>0.718276</td>\n",
       "      <td>19.157937</td>\n",
       "      <td>68.907176</td>\n",
       "      <td>49.749239</td>\n",
       "      <td>0.721975</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75003.0</th>\n",
       "      <td>0.11005</td>\n",
       "      <td>0.33703</td>\n",
       "      <td>22.010</td>\n",
       "      <td>67.406</td>\n",
       "      <td>78.382</td>\n",
       "      <td>56.372</td>\n",
       "      <td>0.719196</td>\n",
       "      <td>19.789984</td>\n",
       "      <td>68.411608</td>\n",
       "      <td>48.621624</td>\n",
       "      <td>0.710722</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75004.0</th>\n",
       "      <td>0.11133</td>\n",
       "      <td>0.32937</td>\n",
       "      <td>22.266</td>\n",
       "      <td>65.874</td>\n",
       "      <td>78.126</td>\n",
       "      <td>55.860</td>\n",
       "      <td>0.714999</td>\n",
       "      <td>23.098220</td>\n",
       "      <td>75.135216</td>\n",
       "      <td>52.036996</td>\n",
       "      <td>0.692578</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75490.0</th>\n",
       "      <td>0.08834</td>\n",
       "      <td>0.31406</td>\n",
       "      <td>17.668</td>\n",
       "      <td>62.812</td>\n",
       "      <td>72.256</td>\n",
       "      <td>54.588</td>\n",
       "      <td>0.755481</td>\n",
       "      <td>12.633882</td>\n",
       "      <td>50.280878</td>\n",
       "      <td>37.646996</td>\n",
       "      <td>0.748734</td>\n",
       "      <td>19.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75491.0</th>\n",
       "      <td>0.08578</td>\n",
       "      <td>0.30385</td>\n",
       "      <td>17.156</td>\n",
       "      <td>60.770</td>\n",
       "      <td>69.192</td>\n",
       "      <td>52.036</td>\n",
       "      <td>0.752052</td>\n",
       "      <td>9.181600</td>\n",
       "      <td>47.080706</td>\n",
       "      <td>37.899106</td>\n",
       "      <td>0.804982</td>\n",
       "      <td>19.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75492.0</th>\n",
       "      <td>0.08450</td>\n",
       "      <td>0.29746</td>\n",
       "      <td>16.900</td>\n",
       "      <td>59.492</td>\n",
       "      <td>67.406</td>\n",
       "      <td>50.506</td>\n",
       "      <td>0.749280</td>\n",
       "      <td>9.508180</td>\n",
       "      <td>46.423067</td>\n",
       "      <td>36.914886</td>\n",
       "      <td>0.795184</td>\n",
       "      <td>19.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75493.0</th>\n",
       "      <td>0.08450</td>\n",
       "      <td>0.29236</td>\n",
       "      <td>16.900</td>\n",
       "      <td>58.472</td>\n",
       "      <td>66.130</td>\n",
       "      <td>49.230</td>\n",
       "      <td>0.744443</td>\n",
       "      <td>8.628580</td>\n",
       "      <td>46.019710</td>\n",
       "      <td>37.391129</td>\n",
       "      <td>0.812503</td>\n",
       "      <td>19.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75494.0</th>\n",
       "      <td>0.08323</td>\n",
       "      <td>0.29491</td>\n",
       "      <td>16.646</td>\n",
       "      <td>58.982</td>\n",
       "      <td>65.618</td>\n",
       "      <td>48.972</td>\n",
       "      <td>0.746320</td>\n",
       "      <td>5.807247</td>\n",
       "      <td>42.804888</td>\n",
       "      <td>36.997641</td>\n",
       "      <td>0.864332</td>\n",
       "      <td>19.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>495 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  NO      NOx  NO_ppm  NOx_ppm  NOx_ppm_ta     NO2   NO2/NOx  \\\n",
       "Crank Angle                                                                    \n",
       "75000.0      0.10750  0.37659  21.500   75.318      73.276  51.776  0.706589   \n",
       "75001.0      0.10750  0.36000  21.500   72.000      75.828  54.328  0.716464   \n",
       "75002.0      0.11005  0.34979  22.010   69.958      78.126  56.116  0.718276   \n",
       "75003.0      0.11005  0.33703  22.010   67.406      78.382  56.372  0.719196   \n",
       "75004.0      0.11133  0.32937  22.266   65.874      78.126  55.860  0.714999   \n",
       "...              ...      ...     ...      ...         ...     ...       ...   \n",
       "75490.0      0.08834  0.31406  17.668   62.812      72.256  54.588  0.755481   \n",
       "75491.0      0.08578  0.30385  17.156   60.770      69.192  52.036  0.752052   \n",
       "75492.0      0.08450  0.29746  16.900   59.492      67.406  50.506  0.749280   \n",
       "75493.0      0.08450  0.29236  16.900   58.472      66.130  49.230  0.744443   \n",
       "75494.0      0.08323  0.29491  16.646   58.982      65.618  48.972  0.746320   \n",
       "\n",
       "                NO_Avg    NOx_Avg    NO2_Avg  NO2/NO_Avg  Avg_Time  \n",
       "Crank Angle                                                         \n",
       "75000.0      17.561976  69.219475  51.657498    0.746286      0.00  \n",
       "75001.0      21.408024  70.656808  49.248784    0.697014      0.04  \n",
       "75002.0      19.157937  68.907176  49.749239    0.721975      0.08  \n",
       "75003.0      19.789984  68.411608  48.621624    0.710722      0.12  \n",
       "75004.0      23.098220  75.135216  52.036996    0.692578      0.16  \n",
       "...                ...        ...        ...         ...       ...  \n",
       "75490.0      12.633882  50.280878  37.646996    0.748734     19.60  \n",
       "75491.0       9.181600  47.080706  37.899106    0.804982     19.64  \n",
       "75492.0       9.508180  46.423067  36.914886    0.795184     19.68  \n",
       "75493.0       8.628580  46.019710  37.391129    0.812503     19.72  \n",
       "75494.0       5.807247  42.804888  36.997641    0.864332     19.76  \n",
       "\n",
       "[495 rows x 12 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################Break the above function into small ones ############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter_NONOX( ):\n",
    "    This function filters the original dataframe to contain only NO, NOx (V) indexed by crank angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Filter_NONOX(Assembled_Data):\n",
    "#-------------------------------------------------tidy up the original dataframe-----------------------------------------\n",
    "    #replace variable names for convenience\n",
    "    a = Assembled_Data\n",
    "    # drop all unneccessary columns, and the units row.\n",
    "    a = a[['Crank Angle', 'NO', 'NOx']].drop([0])\n",
    "    # change data types from strings to floats\n",
    "    a = a.astype('float64')\n",
    "    # drop all rows with 0 values\n",
    "    a = a[a.NO != 0.0000]\n",
    "    #reset the index and drop original index column\n",
    "    a = a.reset_index().drop(['index'], axis=1)\n",
    "    #set crank angle as the index\n",
    "    a = a.set_index('Crank Angle')\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b1 = Filter_NONOX(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TimeAlignmentNO2( )\n",
    "With the user supplying NONOX filtered dataframe:\n",
    "    This function adds columns for:\n",
    "        NO NOX in ppm\n",
    "        NOX timealigned\n",
    "        NO2 and NO2/NOX\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TimeAlignmentNO2(Filter_NONOX_Output_, time_alignment_constant_):\n",
    "#-------------------------------------------------tidy up the original dataframe-----------------------------------------\n",
    "    #replace variable names for convenience\n",
    "    a = Filter_NONOX_Output_\n",
    "    \n",
    "#---------------------------------------------Generate basic data from existing data----------------------------------------\n",
    "    # Create two columns for NONOX in ppm\n",
    "    a['NO_ppm'] = a['NO'] * 200\n",
    "    a['NOx_ppm'] = a['NOx'] * 200\n",
    "    # Create NOx time aligned by shifting Nox_ppm values up by time constant amount \n",
    "    a['NOx_ppm_ta'] = a['NOx_ppm'].shift(-time_alignment_constant_)\n",
    "    # Create NO2 column\n",
    "    a['NO2'] = a['NOx_ppm_ta'] - a['NO_ppm']\n",
    "    # Create NO2/NOx column\n",
    "    a['NO2/NOx'] = a['NO2'] / a['NOx_ppm_ta']\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c1 = TimeAlignmentNO2(b1, time_alignment_constant_ = 265)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NONOX_Cyclic_Avg( ):\n",
    "    A funtion that calculates the average of NO NOx within sampling window from CAD 75000 onwards, and generate NO2 NO2/NOX average.\n",
    "\n",
    "INPUT:\n",
    "    Output of TimeAlignmentNO2\n",
    "    TDC EVO EVC\n",
    "    NOoffset: the magical 390 in excel sheet 255\n",
    "    Engine period of 720\n",
    "OUTPUT: \n",
    "    After this function, one should be able to obtain a dataframe containing all NONOX data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NONOX_Cyclic_Avg(TimeAlignmentNO2_Output_, TDC, EVO, EVC, NOoffset,Start_Crank_Angle=75000):\n",
    "    #simplify variable name for convenience\n",
    "    Engine_Cycle_Period_=720\n",
    "    SCA = Start_Crank_Angle\n",
    "    a = TimeAlignmentNO2_Output_\n",
    "    p = Engine_Cycle_Period_\n",
    "    x = 0\n",
    "    while (x*p - NOoffset + TDC + EVC < a.shape[0]):\n",
    "        a.loc[SCA+x, 'NO_Avg'] = a['NO_ppm'].loc[SCA + x*p - NOoffset + TDC + EVO : SCA + x*p - NOoffset + TDC + EVC].mean()\n",
    "        a.loc[SCA+x, 'NOx_Avg'] = a['NOx_ppm'].loc[SCA + x*p + TDC + EVO : SCA + x*p + TDC + EVC].mean()\n",
    "        x = x + 1\n",
    "        \n",
    "    a['NO2_Avg'] = a['NOx_Avg'] - a['NO_Avg']\n",
    "    a['NO2/NO_Avg'] = a['NO2_Avg'] / a['NOx_Avg']\n",
    "\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d1 = NONOX_Cyclic_Avg(c1, TDC=600, EVO=128,EVC=382,NOoffset=390)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NO_NOx_plotter( )\n",
    "Plots NO NOx data against crank angle.\n",
    "\n",
    "Input:\n",
    "    The NONOx filtered dataframe.\n",
    "    Start and end CAD he wishes to plot, by default 0 - 4319999.\n",
    "    Whether to plot NO, NOx or both\n",
    "    y lower and upper limit, 0 and 9 by default, which is the range of the entire dataframe.\n",
    "\n",
    "Output: NO NOX plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NONOX_v_plotter(Filtered_data_, NOoffset_, Start_Crank_Angle_ = -360, End_Crank_Angle_ = 431640, plot_NO = True, plot_NOx = True, y_lower_limit_ = 0, y_upper_limit_ = 3):\n",
    "    axes = plt.gca()\n",
    "    a = Filtered_data_\n",
    "    c = NOoffset_\n",
    "    sca = Start_Crank_Angle_\n",
    "    eca = End_Crank_Angle_\n",
    "    yll = y_lower_limit_\n",
    "    yul = y_upper_limit_\n",
    "    #FROM EXCEL SHEET 255, CRANK ANGLE STARTS AT 75390, NO STARTS AT 75000\n",
    "    a['NOshifted'] = a['NO'].shift(c)\n",
    "    if plot_NO == True and plot_NOx == True:\n",
    "        a.reset_index().reset_index().iloc[sca + 360 : eca + 360].plot(kind='line', x='index', y='NOshifted', label = 'NO', ylim = (yll , yul), ax=axes)\n",
    "        a.reset_index().reset_index().iloc[sca + 360 : eca + 360].plot(kind='line', x='index', y='NOx', ylim = (yll , yul), ax=axes)\n",
    "    elif plot_NO == True and plot_NOx == False:\n",
    "        a.reset_index().reset_index().iloc[sca + 360 : eca + 360].plot(kind='line', x='index', y='NOshifted', label = 'NO', ylim = (yll , yul), ax=axes)\n",
    "    else:\n",
    "        a.reset_index().reset_index().iloc[sca + 360 : eca + 360].plot(kind='line', x='index', y='NOx', ylim = (yll , yul), ax=axes)\n",
    "    axes.set(xlabel=\"Crank Angle\", ylabel=\"V\")\n",
    "    a.drop(columns=['NOshifted'])\n",
    "    plt.show()\n",
    "#as an example, we want to plot from \"engine\", from 205000 CAD to 215000 degree, the variation of NOx only:\n",
    "#NO_NOx_plotter(engine, 205000, 215000, False, True)\n",
    "#or, as False = 0, and True = 1:\n",
    "#NO_NOx_plotter(engine, 205000, 215000, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NONOX_in_V = NONOX_v_plotter(d1, NOoffset_=390, Start_Crank_Angle_=75000,End_Crank_Angle_=77000,plot_NO=True,plot_NOx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NONOX_ppm_plotter(Filtered_data_, NOoffset_, Start_Crank_Angle_ = -360, End_Crank_Angle_ = 431640, plot_NO = True, plot_NOx = True, plot_ratio = True, y_lower_limit_ = 0, y_upper_limit_ = 600, ylwrlmt_right = -0.5, yuprlmt_right = 0.5):\n",
    "    axes = plt.gca()\n",
    "    a = Filtered_data_\n",
    "    c = NOoffset_\n",
    "    sca = Start_Crank_Angle_\n",
    "    eca = End_Crank_Angle_\n",
    "    yll = y_lower_limit_\n",
    "    yul = y_upper_limit_\n",
    "    yllr = ylwrlmt_right\n",
    "    yulr = yuprlmt_right\n",
    "    \n",
    "    #shifting the columns to plot as the excel sheets!\n",
    "    a['NOshifted_ppm'] = a['NO_ppm'].shift(-c)\n",
    "    a['NO2/NOxshifted'] = a['NO2/NOx'].shift(-c)\n",
    "    if plot_NO == True and plot_NOx == True and plot_ratio == True:\n",
    "        a.reset_index().reset_index().iloc[sca + 360 : eca + 360].plot(kind='line', x='index', y='NOshifted_ppm', label = 'NO_ppm', ylim = (yll , yul), ax=axes)\n",
    "        a.reset_index().reset_index().iloc[sca + 360 : eca + 360].plot(kind='line', x='index', y='NOx_ppm', ylim = (yll , yul), ax=axes)\n",
    "        a.reset_index().reset_index().iloc[sca + 360 : eca + 360].plot(kind='line', x='index', y='NO2/NOxshifted',secondary_y=True, label = 'NO2/NOx', ax=axes)\n",
    "        axes.right_ax.set_ylim(yllr,yulr)\n",
    "    elif plot_NO == True and plot_NOx == True and plot_ratio == False:\n",
    "        a.reset_index().reset_index().iloc[sca + 360 : eca + 360].plot(kind='line', x='index', y='NOshifted_ppm', label = 'NO_ppm', ylim = (yll , yul), ax=axes)\n",
    "        a.reset_index().reset_index().iloc[sca + 360 : eca + 360].plot(kind='line', x='index', y='NOx_ppm', ylim = (yll , yul), ax=axes)\n",
    "    elif plot_NO == True and plot_NOx == False and plot_ratio == True:\n",
    "        a.reset_index().reset_index().iloc[sca + 360 : eca + 360].plot(kind='line', x='index', y='NOshifted_ppm', label = 'NO_ppm', ylim = (yll , yul), ax=axes)\n",
    "        a.reset_index().reset_index().iloc[sca + 360 : eca + 360].plot(kind='line', x='index', y='NO2/NOxshifted',secondary_y=True, label = 'NO2/NOx', ax=axes)\n",
    "        axes.right_ax.set_ylim(yllr,yulr)\n",
    "    elif plot_NO == True and plot_NOx == False and plot_ratio == False:\n",
    "        a.reset_index().reset_index().iloc[sca + 360 : eca + 360].plot(kind='line', x='index', y='NOshifted_ppm', label = 'NO_ppm', ylim = (yll , yul), ax=axes)\n",
    "    elif plot_NO == False and plot_NOx == True and plot_ratio == True:\n",
    "        a.reset_index().reset_index().iloc[sca + 360 : eca + 360].plot(kind='line', x='index', y='NOx_ppm', ylim = (yll , yul), ax=axes)\n",
    "        a.reset_index().reset_index().iloc[sca + 360 : eca + 360].plot(kind='line', x='index', y='NO2/NOxshifted',secondary_y=True, label = 'NO2/NOx', ax=axes)\n",
    "        axes.right_ax.set_ylim(yllr,yulr)\n",
    "    elif plot_NO == False and plot_NOx == True and plot_ratio == False:\n",
    "        a.reset_index().reset_index().iloc[sca + 360 : eca + 360].plot(kind='line', x='index', y='NOx_ppm', ylim = (yll , yul), ax=axes)\n",
    "    elif plot_NO == False and plot_NOx == False and plot_ratio == True:\n",
    "        a.reset_index().reset_index().iloc[sca + 360 : eca + 360].plot(kind='line', x='index', y='NO2/NOxshifted',secondary_y=True, label = 'NO2/NOx', ax=axes)\n",
    "        axes.right_ax.set_ylim(yllr,yulr)\n",
    "    axes.set(xlabel=\"Crank Angle\", ylabel=\"ppm\")\n",
    "    #a = a.drop(columns=['NOshifted_ppm', 'NO2/NOxshifted'])\n",
    "    plt.show()\n",
    "    return a\n",
    "#as an example, we want to plot from \"engine\", from 205000 CAD to 215000 degree, the variation of NOx only:\n",
    "#NO_NOx_plotter(engine, 205000, 215000, False, True)\n",
    "#or, as False = 0, and True = 1:\n",
    "#NO_NOx_plotter(engine, 205000, 215000, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NONOX_in_ppm = NONOX_ppm_plotter(d1,NOoffset_=390,Start_Crank_Angle_=77000,End_Crank_Angle_=80000,plot_NO=True,plot_NOx=False,plot_ratio=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter_Shifted( )\n",
    "    The function aims to clean up and get rid of the extra shifted columns generated from the plots functions\n",
    "    as I did not manage to find a way to stop the functions generating the extra columns\n",
    "INPUT:\n",
    "    The dataframe after plots, two boolean variables to indicate whether the user has used the two plot functions\n",
    "    by default, the user is assumed to NOT have plotted, hence the function wont do anything\n",
    "\n",
    "OUTPUT:\n",
    "    Cleaned dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Filter_Shifted(Plots_Output, NO_v_plotted = False, NO_ratio_ppm_plotted = False):\n",
    "    a = Plots_Output\n",
    "    if NO_v_plotted == True and NO_ratio_ppm_plotted == True:\n",
    "        a = a.drop(columns = ['NOshifted', 'NOshifted_ppm', 'NO2/NOxshifted'])\n",
    "    elif NO_v_plotted == True and NO_ratio_ppm_plotted == False:\n",
    "        a = a.drop(columns = ['NOshifted'])\n",
    "    elif NO_v_plotted == False and NO_ratio_ppm_plotted == True:\n",
    "        a = a.drop(columns = ['NOshifted_ppm', 'NO2/NOxshifted'])\n",
    "\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e1 = Filter_Shifted(d1, NO_v_plotted=True, NO_ratio_ppm_plotted= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time( )\n",
    "    This function calculates the average time taken after each crank angle, and allows user to input the starting crank angle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Time(dataframe, Start_Crank_Angle):\n",
    "    a = dataframe\n",
    "    s = Start_Crank_Angle\n",
    "    Avg_Time = []\n",
    "    for value in a.index:\n",
    "        Avg_Time.append((360 + value)*0.04)\n",
    "    a['Avg_Time'] = Avg_Time\n",
    "    a['Avg_Time'] = a['Avg_Time'].shift(s + 360)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f1 = Time(d1,75000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################## PRESSURE FUNCTIONS FROM NOW ON##############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PMAX_DATA( )\n",
    "    This a big function that takes in the raw data output from File_Assembler(). It returns a dataframe that contains PMAX\n",
    "    data indexed by the starting crank angle supplied by user, same as the work done in excel.\n",
    "    \n",
    "    Due to the length of the function, no comments are added.\n",
    "    \n",
    "    The function will be broken down into smaller parts later on, and the explanations and comments will be attached there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PMAX_DATA(Assembled_Data, Start_Crank_Angle_):\n",
    "    p = Assembled_Data\n",
    "    p = p[['Crank Angle', 'PCYL1']].drop([0]).astype('float64').set_index(['Crank Angle'])\n",
    "    \n",
    "    rand_sampling_index = np.random.randint(1,10)\n",
    "    sample_index = pd.DataFrame([1,2,3,4,5,6,7,8,9,10]).sample(frac = 1)\n",
    "\n",
    "    sample_n_360 = p.loc[-360].sample(n = 1)\n",
    "    \n",
    "    n1 = int((p.loc[-359:-1].count())/10)\n",
    "    randomizercolumn1 = pd.concat([sample_index] * n1)\n",
    "    randomizercolumn1.index = p.loc[-359:-1].index\n",
    "    t1 = pd.concat([randomizercolumn1, p.loc[-359:-1]], axis = 1)\n",
    "    t1 = t1[t1[0] == rand_sampling_index]\n",
    "    first_part = t1.drop([0], axis = 1)\n",
    "    \n",
    "    sample_0 = p.loc[0].sample(n = 1)\n",
    "        \n",
    "    n2 = int((p.loc[1:431639].count())/10)\n",
    "    randomizercolumn2 = pd.concat([sample_index] * n2)\n",
    "    randomizercolumn2.index = p.loc[1:431639].index\n",
    "    t2 = pd.concat([randomizercolumn2, p.loc[1:431639]], axis = 1)\n",
    "    t2 = t2[t2[0] == rand_sampling_index]\n",
    "    second_part = t2.drop([0], axis = 1)\n",
    "\n",
    "    sample_431640 = p.loc[431640].sample(n = 1)\n",
    "    \n",
    "    P_sampled = pd.concat([sample_n_360, first_part, sample_0, second_part, sample_431640])\n",
    "    \n",
    "    Period_ = 720\n",
    "    SCA = Start_Crank_Angle_\n",
    "    PMAX_ = pd.DataFrame([], columns = ['PMAX', 'Crank Angle']).set_index('Crank Angle')\n",
    "    x = 0\n",
    "\n",
    "    while ((SCA+Period_*(x+1)-1) < P_sampled.shape[0]):\n",
    "        PMAX_.loc[SCA+x] = float(P_sampled.loc[SCA+Period_*x:SCA+Period_*(x+1)-1].max())\n",
    "        x = x + 1\n",
    "        \n",
    "    return PMAX_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = PMAX_DATA(a, 75000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter_PCYL1( ):\n",
    "\n",
    "Input:\n",
    "    Data from File_Assembler or File_Loader.\n",
    "\n",
    "Output: \n",
    "    Dataframe that contains only Crank Angle, PCYL1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Filter_PCYL1(Assembled_Data):\n",
    "    P_Dataframe_ = Assembled_Data\n",
    "    # drop all unneccessary columns, and the units row.\n",
    "    P_Dataframe_ = P_Dataframe_[['Crank Angle', 'PCYL1']].drop([0])\n",
    "    # change data types from strings to floats\n",
    "    P_Dataframe_ = P_Dataframe_.astype('float64')\n",
    "    #reset the index and drop original index column\n",
    "    P_Dataframe_ = P_Dataframe_.set_index(['Crank Angle'])\n",
    "    #Assembled_Data_filtered = Assembled_Data_filtered.reset_index().drop(['index'], axis=1)\n",
    "    #Make Crank Angle start at 0 instead of -360\n",
    "    #Assembled_Data_filtered['Crank Angle'] = Assembled_Data_filtered['Crank Angle'] + 360\n",
    "\n",
    "    return P_Dataframe_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b2 = Filter_PCYL1(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Psample( ) returns a dataframe that contains sampled PCYL1 data.\n",
    "\n",
    "The relatively quick sampling is achieved by appending a column of integer 1 to 10 in random order, and sample a specific\n",
    "row with a random number generated at start of the function.\n",
    "\n",
    "With CAD -360, 0, 431640 containing less than 10 rows, we have to treat them separately, hence the entire function\n",
    "contains 5 parts. In the end, we concatenate them all together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    " def Psample(P_Dataframe_):\n",
    "    p = P_Dataframe_\n",
    "    \n",
    "    #generate a random integer for sampling\n",
    "    rand_sampling_index = np.random.randint(1,10)\n",
    "    #create index 1:10\n",
    "    sample_index = pd.DataFrame([1,2,3,4,5,6,7,8,9,10])\n",
    "    #Randomize the sample_index\n",
    "    sample_index = sample_index.sample(frac = 1)\n",
    "    \n",
    "    \n",
    "    #randomly sample a data for -ve 360\n",
    "    sample_n_360 = P_Dataframe_.loc[-360].sample(n = 1)\n",
    "\n",
    "    #deal with all CADs inbetween -360 and 0\n",
    "    #dupilicate random index by [(rows -359:-1 )/10 = n1] number of times\n",
    "    n1 = int((p.loc[-359:-1].count())/10)\n",
    "    #concatenate all 1-10 repeats for n1 times in a column\n",
    "    randomizercolumn1 = pd.concat([sample_index] * n1)\n",
    "    #copy the index of input DataFrame, which is 'Crank Angle', to the newly created randomizer column\n",
    "    randomizercolumn1.index = p.loc[-359:-1].index\n",
    "    #Now that both the dataframe and randomizer column are indexed by 'Crank Angle', we concatenate them side by side\n",
    "    t1 = pd.concat([randomizercolumn1, p.loc[-359:-1]], axis = 1)\n",
    "    #Use the random number generated at first to sample. The randomizer column has column name as '0'\n",
    "    t1 = t1[t1[0] == rand_sampling_index]\n",
    "    #Now drop the randomizer column with column name '0'.\n",
    "    first_part = t1.drop([0], axis = 1)\n",
    "    \n",
    "    #Deal with 0\n",
    "    sample_0 = p.loc[0].sample(n = 1)\n",
    "        \n",
    "    #all CADS inbetween 0 and 431640 same before.\n",
    "    n2 = int((p.loc[1:431639].count())/10)\n",
    "    randomizercolumn2 = pd.concat([sample_index] * n2)\n",
    "    randomizercolumn2.index = p.loc[1:431639].index\n",
    "    t2 = pd.concat([randomizercolumn2, p.loc[1:431639]], axis = 1)\n",
    "    t2 = t2[t2[0] == rand_sampling_index]\n",
    "    second_part = t2.drop([0], axis = 1)\n",
    "\n",
    "    #Deal with 431640\n",
    "    sample_431640 = p.loc[431640].sample(n = 1)\n",
    "    \n",
    "    #concatenate all 5 parts together vertically.\n",
    "    P_sampled = pd.concat([sample_n_360, first_part, sample_0, second_part, sample_431640])\n",
    "    \n",
    "    \n",
    "    return P_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c2 = Psample(b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Psample_MAXMAX( )\n",
    "    This is a test function which instead of sampling, take the maximum PCLY1 per CAD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Psample_MAXMAX(P_Dataframe_):\n",
    "    p = P_Dataframe_\n",
    "    P_sampled = P_Dataframe_.groupby(p.index).max()\n",
    "    return P_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c2 = Psample_MAXMAX(b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PMAX( ):\n",
    "Extracts cyclic maximum PCYL1.\n",
    "\n",
    "INPUT:\n",
    "    PCYL1 filtered dataframe\n",
    "    Offset of engine cycle (how much CAD does the engine go through before the first recorded cycle)\n",
    "    Engine cycle period\n",
    "OUTPUT:\n",
    "    A dataframe that contains maximum PCYL1 for every engine cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PMAX(P_sampled, Start_Crank_Angle_ = -360):\n",
    "    Period_ = 720\n",
    "    SCA = Start_Crank_Angle_\n",
    "    PMAX_ = pd.DataFrame([], columns = ['PMAX', 'Crank Angle']).set_index('Crank Angle')\n",
    "    x = 0\n",
    "\n",
    "    while ((SCA+Period_*(x+1)-1) < P_sampled.shape[0]):\n",
    "        #Find the max pressure value for every 720 degree cycle, append to the PMAX_ dataframe.\n",
    "        PMAX_.loc[SCA+x] = float(P_sampled.loc[SCA+Period_*x:SCA+Period_*(x+1)-1].max())\n",
    "        #increment x\n",
    "        x = x + 1\n",
    "        \n",
    "    return PMAX_\n",
    "#The output dataframe should have its index as the number of cycles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d2 = PMAX(c2, Start_Crank_Angle_=75000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge_PMAX_NONOX()\n",
    "    Merge the two input NONOX and Pmax dataframe together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Merge_PMAX_NONOX(NONOX_Dataframe_, Pmax_Dataframe_):\n",
    "    df1 = NONOX_Dataframe_\n",
    "    df2 = Pmax_Dataframe_\n",
    "    df3 = pd.concat([df1, df2], axis = 1)\n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Merged = Merge_PMAX_NONOX(d1, d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation_NOavg_PMAX() makes a scatter plot of NONOX and also returns R value, the default limits are set according excel files, for reasons which i dont know of.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Correlation_NOavg_PMAX_plot(Merged_Pmax_NONOX_dataframe, PMAXlower_CAD = 75000, PMAXupper_CAD = 75140, NONOXlower_CAD = 75001, NONOXupper_CAD = 75141, plotNO = True, plotNOX = False):\n",
    "    df3 = Merged_Pmax_NONOX_dataframe\n",
    "    pl = PMAXlower_CAD\n",
    "    pu = PMAXupper_CAD\n",
    "    nl = NONOXlower_CAD\n",
    "    nu = NONOXupper_CAD\n",
    "    #Regression plots with \n",
    "    if plotNO == True:\n",
    "        sns.regplot(y=df3['PMAX'].loc[pl:pu],x=df3['NO_Avg'].loc[nl:nu],data=df3,fit_reg=True)\n",
    "        Rsquared = df3['PMAX'].corr(df3['NO_Avg'])\n",
    "    elif plotNOX == True:\n",
    "        sns.regplot(y=df3['PMAX'].loc[pl:pu],x=df3['NOx_Avg'].loc[nl:nu],data=df3,fit_reg=True)\n",
    "        Rsquared = df3['PMAX'].corr(df3['NOx_Avg'])\n",
    "        print(Rsquared)\n",
    "    return Rsquared\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation_NOavg_PMAX_plot(Merged, PMAXlower_CAD=75000,PMAXupper_CAD=75140,NONOXlower_CAD=75001,NONOXupper_CAD=75141,plotNO=True,plotNOX=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NO2_NOx_ratio_vs_avgtime()\n",
    "    plots a scatter plot of the ratio against avg time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NO2_NOx_ratio_vs_avgtime(DataframeWithTime_, Start_Crank_Angle_, End_Crank_Angle_):\n",
    "    df = DataframeWithTime_\n",
    "    SCA = Start_Crank_Angle_\n",
    "    ECA = End_Crank_Angle_\n",
    "    df1 = df[SCA:ECA]\n",
    "    df1.plot.scatter(x='Avg_Time',y='NO2/NO_Avg', c='DarkBlue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NO2_NOx_ratio_vs_avgtime(f1, 75000, 431639)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------QUENCH AND DRIFT-------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DriftCorrections( )\n",
    "    Replicate the 'drift correction' excel sheet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DriftCorrections(NO0_start, NOS_start, NOx0_start, NOxS_start, NO0_end, NOS_end, NOx0_end, NOxS_end):\n",
    "    #First we make the left part of excel sheet which contains all user input information\n",
    "    Start_End_data = pd.DataFrame(columns = [' ','Start', 'End'])\n",
    "    Start_End_data[' '] = ['number','NO0', 'NOS', 'NOx0', 'NOxS']\n",
    "    Start_End_data['Start'] = [np.nan, NO0_start, NOS_start, NOx0_start, NOxS_start]\n",
    "    Start_End_data['End'] = [np.nan, NO0_end, NOS_end, NOx0_end, NOxS_end]\n",
    "    \n",
    "    #Make the right part of the excel sheet, containing 12 tests and check.\n",
    "    correction_data = pd.DataFrame([], columns = ['1','2','3','4','5','6','7','8','9','10','11','12','check'])\n",
    "    correction_data.loc[0, 0:12] = list(x for x in range(1,13))\n",
    "    \n",
    "    #ROW NO0\n",
    "    #Initialize the first value of the row\n",
    "    correction_data.loc[1, '1'] = NO0_start\n",
    "    #Use the same algorithm as excel to fill the other values\n",
    "    for x in range(1,12):\n",
    "        correction_data.iloc[1,x] = correction_data.iloc[1,x-1] - (NO0_end - NO0_start)/11\n",
    "    \n",
    "    #Row NOS\n",
    "    #Initialize the first value of the row\n",
    "    correction_data.loc[2,'1'] = ((NOS_end-NOS_start)/NOS_end)*((correction_data.iloc[0,0])-1)/(correction_data.iloc[0,11]) + 1    \n",
    "    #Use the same algorithm as excel to fill the other values\n",
    "    for x in range(1,12):\n",
    "        correction_data.iloc[2,x] = ((NOS_end-NOS_start)/NOS_start)*((correction_data.iloc[0,x])-1)/((correction_data.iloc[0,11])-1) + 1\n",
    "    # 'Check' column\n",
    "    correction_data.loc[2,'check'] = NOS_end/(correction_data.iloc[2,11])\n",
    "    \n",
    "    #The next two rows are similar to the first two, so comments are omitted.\n",
    "    \n",
    "    #Row NOX0\n",
    "    correction_data.loc[3, '1'] = NOx0_start\n",
    "    for x in range(1,12):\n",
    "        correction_data.iloc[3,x] = correction_data.iloc[3,x-1] - (NOx0_end - NOx0_start)/11\n",
    "        \n",
    "    #Row NOXs\n",
    "    correction_data.loc[4,'1'] = ((NOxS_end-NOxS_start)/NOxS_end)*((correction_data.iloc[0,0])-1)/(correction_data.iloc[0,11]) + 1    \n",
    "    for x in range(1,12):\n",
    "        correction_data.iloc[4,x] = ((NOxS_end-NOxS_start)/NOxS_start)*((correction_data.iloc[0,x])-1)/(correction_data.iloc[0,11]-1) + 1\n",
    "    correction_data.loc[4,'check'] = NOxS_end/(correction_data.iloc[4,11])\n",
    "    \n",
    "    #Finally, append the two dataframes together and set index to be NO0, NOS, NOx0, NOxS\n",
    "    data = pd.concat([Start_End_data, correction_data], axis=1).set_index(' ')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1500 3bar cycle excelsheet example:\n",
    "\n",
    "#D = DriftCorrections(0,2500,0,2500,0,2515,15,2545)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In specifying the path, one should alway add an 'r' in front so that '\\' is treated as a raw string\n",
    "# And a '\\' at the back.\n",
    "#As shown in the example here\n",
    "path = r'C:\\Users\\Eric Zhong\\Documents\\2.INTERNSHIP\\RESEARCH\\Fast_NOx-20200612T071734Z-001\\Fast_NOx'\n",
    "file = '1500 3bar cycle analysis'\n",
    "filename = '1500 3bar cycle analysis.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DriftCorrection(path, filename):\n",
    "    drift = pd.read_excel(path+'\\\\'+filename, sheet_name = 'Drift corrections')\n",
    "    drift = drift.set_index('Unnamed: 0')\n",
    "    return drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = DriftCorrection(path,filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QuenchCorrection( )\n",
    "Reproduce the 'Quench Correction' excel sheet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QuenchCorrection(FuelHC, FuelOC):\n",
    "    #Create a lambda column\n",
    "    data = pd.DataFrame([], columns = ['Lambda'])\n",
    "\n",
    "    #Create the lambda column\n",
    "    #Using list comprehension to create a list of lambda 0 to 10.0 with step size 0.05\n",
    "    Lambda_column = [((100 + 5*x)/100) for x in range(181)]    \n",
    "    data['Lambda'] = Lambda_column\n",
    "    \n",
    "    #CO2 Column\n",
    "    data['CO2'] = 100/(1+(FuelHC/2)+(((4.773*data['Lambda'])-1)*(1+(FuelHC/4)-(FuelOC/2))))\n",
    "    #H2O\n",
    "    data['H2O'] = 100*FuelHC/(2+FuelHC+2*(((4.773*data['Lambda'])-1)*(1+(FuelHC/4)-(FuelOC/2))))\n",
    "    #O2\n",
    "    data['O2'] = 100*(data['Lambda']-1)*(1+(FuelHC/4)-(FuelOC/2))/(1+(FuelHC/2)+(((4.773*data['Lambda'])-1)*(1+(FuelHC/4)-(FuelOC/2))))\n",
    "    #CLD quench\n",
    "    data['CLD quench'] = (1.34*data['H2O'])+(0.26*data['CO2'])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = QuenchCorrection(1.86,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slow_Data( )\n",
    "    Get useful information out of the slow data excel sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Slow_Data(path, filename):\n",
    "    S = pd.read_excel(path+'\\\\'+filename, sheet_name='slow data', na_values=['NA'], usecols = \"CG:CO\")\n",
    "    #Drop the first row containing units, and NAN rows\n",
    "    S = S[1:].dropna()\n",
    "    #Drop all inrelevant columns\n",
    "    S = S[['NO','NOx','MEXA Lambda']]\n",
    "    #Reset the index and drop original index column\n",
    "    S = S.reset_index().drop(['index'], axis = 1)\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = Slow_Data(path,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Read_slow_data_ranges(slowdataranges_path):\n",
    "    file = 'slowdataranges.xlsx'\n",
    "    Slow_data_ranges = pd.read_excel((path + '\\\\' + file), na_values=['NA'])\n",
    "    #change all NaN values to \n",
    "    return Slow_data_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = Read_slow_data_ranges(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DriftCorrectedNONOXavg( )\n",
    "    Add 3 columns of drifted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DriftCorrectedNONOXavg(NONOXdataframe_, DriftcorrectionDataframe_, RunNumber_):\n",
    "    #change variable names for convenience\n",
    "    SCA = Start_Crank_Angle\n",
    "    p = NONOXdataframe_\n",
    "    D = DriftcorrectionDataframe_\n",
    "    c = RunNumber_\n",
    "    #Calculate drift corrections\n",
    "    p['DriftCorrected_NO_Avg'] = (p['NO_Avg'] + D[c].loc['NO0'])/D[c].loc['NOS']\n",
    "    p['DriftCorrected_NOx_Avg'] = (p['NOx_Avg'] + D[c].loc['NOx0'])/D[c].loc['NOxS']\n",
    "    p['DriftCorrected_NO2_Avg'] = p['DriftCorrected_NOx_Avg'] - p['DriftCorrected_NO_Avg']\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R:\\ProgramFiles\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "R:\\ProgramFiles\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "R:\\ProgramFiles\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "u = DriftCorrectedNONOXavg(Merged,D,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import_Lambda( )\n",
    "    Reads the lambda column from excel file and append it to the NONOXdataframe, so we can do quench analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Append_Slow_Data(NONOXDataframe,RangesDataframe,Slowdataframe,QuenchCorrectionDataframe,file,RunNumber):\n",
    "    p = NONOXDataframe\n",
    "    R = RangesDataframe\n",
    "    S = Slowdataframe\n",
    "    #find the location of the range limits in ranges dataframe\n",
    "    loc_low = RunNumber*2 - 2\n",
    "    loc_high = RunNumber*2 - 1\n",
    "    #Use the corresponding values at loc_low/loc_high to get ranges of lambda values to use\n",
    "    Lambda_low = int(R[file].loc[loc_low])\n",
    "    Lambda_high = int(R[file].loc[loc_high])\n",
    "    #[Lambda_low:Lambda_high] is the range of slow data to use at current filename, current runnumber.\n",
    "    S1 = S[Lambda_low:Lambda_high]\n",
    "    #truncate NONOXDataframe to the same size as S1, for concatenation\n",
    "    SCA = p.index[0]\n",
    "    p1 = p[SCA:SCA+(Lambda_high-Lambda_low)-1]\n",
    "    #set S1's index according to p1, crank angle degrees\n",
    "    S1 = S1.set_index(p1.index)\n",
    "    #concatenate\n",
    "    p2 = pd.concat([p1,S1], axis = 1)\n",
    "    \n",
    "    return p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "u1 = Append_Slow_Data(u,R,S,Q,file,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quench_Correct(Merged,R,S,Q,file,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Import_Lambda(NONOXDataframefrom75000CAD, path, filename = '1500 3bar cycle analysis.xlsx'):\n",
    "    p = NONOXDataframefrom75000CAD\n",
    "    Lambda = pd.read_excel((path + '\\\\' + filename), sheet_name='slow data', na_values=['NA'], usecols = \"CO\")\n",
    "    #get rid of first row containing '#'\n",
    "    Lambda = Lambda[1:]\n",
    "    #extend the grabbed lambda column so that its has the same height as NONOXDataframe\n",
    "    fill = pd.DataFrame([], columns = ['MEXA Lambda'])\n",
    "    fill['MEXA Lambda'] = [np.nan] * (p.shape[0] - Lambda.shape[0])\n",
    "    Lambda = pd.concat([Lambda, fill])\n",
    "    #set index according to NONOXDataframe\n",
    "    Lambda = Lambda.set_index(p.index)\n",
    "    Lambda = Lambda.rename(columns={'MEXA Lambda': 'Slow Lambda'})\n",
    "    \n",
    "    #concatenate\n",
    "    data = pd.concat([p,Lambda], axis=1)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QuenchCorrectedNONOXNO2Ratio()\n",
    "    Add the 3 columns of Quench Corrected data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Append_QuenchCorrected_data(df_with_Driftcor_and_SlowLambda, QuenchCorrection_output_df):\n",
    "    I = df_with_Driftcor_and_SlowLambda\n",
    "    Q = QuenchCorrection_output_df\n",
    "    \n",
    "    #get a column of Lambda rounded to 1 d.p for algo speed\n",
    "    Lrounded = []\n",
    "    for values in I['MEXA Lambda']:\n",
    "        Lrounded.append(round(values, 1))\n",
    "    I['Lrounded'] = Lrounded\n",
    "    #Create the CLD quench Column\n",
    "    CLDcol = []\n",
    "    for values in I['Lrounded']:\n",
    "        n = float(Q[Q['Lambda'] == values]['CLD quench'])\n",
    "        CLDcol.append(n)\n",
    "    I['CLDquench'] = CLDcol\n",
    "    #drop the rounded lambda column\n",
    "    I = I.drop(['Lrounded'], axis = 1)\n",
    "    \n",
    "    #quench corrected NO avg\n",
    "    I['QuenchCorrected_NO_Avg'] = I['DriftCorrected_NO_Avg']*((100 + I['CLDquench'])/100)\n",
    "    #quench corrected NOx avg\n",
    "    I['QuenchCorrected_NOx_Avg'] = I['DriftCorrected_NOx_Avg']*((100 + I['CLDquench'])/100)\n",
    "    #quench corrected NO2 avg\n",
    "    I['QuenchCorrected_NO2_Avg'] = I['QuenchCorrected_NOx_Avg'] - I['QuenchCorrected_NO_Avg']\n",
    "    #quench corrected NO2/NOx avg\n",
    "    I['QuenchCorrected_NO2/NOx'] = I['QuenchCorrected_NO2_Avg']/I['QuenchCorrected_NOx_Avg']\n",
    "    \n",
    "    return I"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
